{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dennismathewjose/Applied-NLP-Learning-Materials/blob/main/IE7500_NLP_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NAME: Dennis Jose\n",
        "#### NUID: 002371781"
      ],
      "metadata": {
        "id": "Q2aKUe4xRhQ8"
      },
      "id": "Q2aKUe4xRhQ8"
    },
    {
      "cell_type": "markdown",
      "id": "bc97d6da",
      "metadata": {
        "id": "bc97d6da"
      },
      "source": [
        "## IE 7500: Applied Natural Language Processing in Engineering - Prof. Larson Ost\n",
        "\n",
        "### Assignment 1: Regular Expressions & Naive Bayes\n",
        "### Total Points: 100 points\n",
        "\n",
        "You will be dealing with movie review data that includes both positive and negative reviews in this assignment. You will use Sentiment Analysis to assess if a given review is positive or negative using the provided dataset.\n",
        "\n",
        "Therefore, we will make use of Naive Bayes algorithm to perform sentiment analysis on the movie review dataset.\n",
        "\n",
        "## Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a03450ac",
      "metadata": {
        "id": "a03450ac"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc584cc2",
      "metadata": {
        "id": "fc584cc2"
      },
      "source": [
        "## Reading the data\n",
        "\n",
        "When reading the data, ensure that the '.csv' file is in the same location where your jupyter notebook is used. This way the files are organized and easy to read using the pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3c9ffbf5",
      "metadata": {
        "id": "3c9ffbf5"
      },
      "outputs": [],
      "source": [
        "## Reading the data and removing columns that are not important.\n",
        "df = pd.read_csv(\"movie_reviews.csv\", sep = ',', encoding = 'latin-1', usecols = lambda col: col not in [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f7fa8ac0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f7fa8ac0",
        "outputId": "2a5d30d3-5da5-41ea-8366-8139ce68aec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "4  Probably my all-time favorite movie, a story o...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-033f67e9-9a2f-4c29-b968-89a63d4dbafa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-033f67e9-9a2f-4c29-b968-89a63d4dbafa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-033f67e9-9a2f-4c29-b968-89a63d4dbafa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-033f67e9-9a2f-4c29-b968-89a63d4dbafa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-50cb6f70-1a8c-49e4-a728-17c4846f9027\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50cb6f70-1a8c-49e4-a728-17c4846f9027')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-50cb6f70-1a8c-49e4-a728-17c4846f9027 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24699,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24600,\n        \"samples\": [\n          \"Lin McAdam (James Stewart) wins a rifle, a Winchester in a shooting contest.Dutch Henry Brown (Stephen McNally) is a bad loser and steals the gun.Lin takes his horse and goes after Dutch and his men and the rifle with his buddy High Spade (Millard Mitchell).The rifle gets in different hands on the way.Will it get back to the right owner? Anthony Mann and James Stewart worked together for the first time and came up with this masterpiece, Winchester '73 (1950).Stewart is the right man to play the lead.He was always the right man to do anything.The terrific Shelley Winters plays the part of Lola Manners and she's great as always.Dan Duryea is terrific at the part of Waco Johnnie Dean.Charles Drake is brilliant as Lola's cowardly boyfriend Steve Miller.Also Wyatt Earp and Bat Masterson are seen in the movie, and they're played by Will Geer and Steve Darrell.The young Rock Hudson plays Young Bull and the young Anthony (Tony) Curtis plays Doan.There are many classic moments in this movie.In one point the group is surrounded by Indians, since this is a western.It's great to watch this survival game where the fastest drawer and the sharpest shooter is the winner.All the true western fans will love this movie.\",\n          \"First, IFC runs Town and Country, and now this. The difference between that stinker and this Pink Panther rip-off is that Town and Country was watchable. This isn't.<br /><br />I can only surmise that the cast signed up for this so they could goof off in Europe on somebody else's dime. Belushi is especially irritating. His scene with Candy (doing a Z-grade Dom DeLuise) was torture. Speaking of torture, five minutes of the talentless Shepherd, and I bet the prisoners at Gitmo would crack like walnuts!<br /><br />The real \\\"Crime\\\" (besides this being green-lighted) is Shepherd's character: a mousy wife who takes a Monte Carlo casino for a half-million bucks! If you buy that, I have some oceanfront property in Arizona you might be interested in!\",\n          \"Well our standards have gone into the toilet. The direction was poor, the acting was mediocre and the writing was amateurish. And those are the good points. Hopefully there won't be a sequel. Otherwise, I might have to leave the country.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df.head() # print head of data frame with help of head function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1749da04",
      "metadata": {
        "id": "1749da04"
      },
      "source": [
        "## Count plot of the output categories: positive or negative\n",
        "\n",
        "Feel free to take a look at the output and whether the classes are balanced or imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c152e8a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "c152e8a4",
        "outputId": "5c577df4-3c47-402e-f538-e7ebd7f59a92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBAAAAK/CAYAAADQ/z7xAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUBNJREFUeJzt3XeUVOX9+PHP0HaXsgvSERCkWVHsCFY0qNiiouiq2GKJqESjxhiNKQZjYk1Ro4lY0dhrYgtYiGhURA0EUYnyVZCfhSadfX5/eHbCsAsXVmBXfb3O2XPce+/MPDPzsO597517cymlFAAAAACrUK+2BwAAAADUfQICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgLAt0wulyv4qlevXjRv3jx22WWXuOmmmyKltN7Gctxxx0Uul4sxY8asl9utKz/+8Y8jl8vFiSeemLnt9OnTo0GDBtGoUaP49NNP18PoIi655JL8+33JJZesdLvi4uLI5XLrZUzrSy6Xiy5dutT2MOqkLl26fOPebwDWLQEB4Ftq6NChMXTo0CgvL4/NNtssxo4dG9/73vfiqKOOqu2hfe12bI455piIiLjvvvti4cKFq9x21KhRsWzZsthvv/2iZcuW62N4Ba6++ur4/PPP1/vjrgtjxoyJXC4Xxx13XG0PBdaq//73v5HL5WL33Xev7aEAFBAQAL6lRo4cGSNHjozbbrst/vnPf8YTTzwRDRo0iLvuuiseffTR9TKGESNGxKRJk2KHHXZYL7dbVzbddNPYdtttY/bs2fHII4+sctvbb789Iv4XHdankpKSmD17dlx55ZXr/bFry6RJk+KZZ56p7WHUSc8880xMmjSptocBwNeIgABARETsvffe+Z3aBx98cL08Zvv27WOTTTaJxo0br5fbrUuVr11lIKjOpEmTYvz48dG8efPYf//919fQ8o477rgoLi6Oa665Jj777LP1/vi1YZNNNolu3brV9jDqpG7dusUmm2xS28MA4GtEQAAgr0+fPhERMW3atILlt912W/Tv3z9KS0ujcePG0bt37xgxYkS1h+svXrw4/vjHP8b2228fLVu2jMaNG0eXLl1i//33j7vuuqtg2xXPZVB5SPr7778fEYXna1j+c+wr3m7JkiXRqlWrKC4ujlmzZlX73N58883I5XKxzTbbVFn397//PQYNGhStW7eOoqKi2HjjjePss89eo3MUHHnkkVG/fv3429/+ttKd88q4MHjw4CgqKsovnzdvXowYMSK22mqrKCsri6ZNm0a3bt1i8ODB8cQTT6z2GLJ06NAhTjnllJg7d2785je/WaPbTps2LYYNGxbdunWL4uLi2GCDDWL//fePf/7zn9Vun1KKP/3pT7HVVltFSUlJtGvXLk488cSYOXPmSs9h8fzzz8ewYcOid+/e0aJFiygpKYlNNtkkfvSjH1V5X4877rjYY489IiLilltuKZgry5/nYcW5c//990cul4sjjjhipc/1nHPOiVwuF9dee23B8vnz58eIESOiT58+0bRp02jatGnstNNOccstt2S/gMsZOXJkfpxvv/12DBkyJNq2bRv16tUriHeTJk2K4447Ljp16hRFRUXRtm3bGDJkSPz73/8uuL8rr7wycrlcnH/++St9zEMPPTRyuVw8/PDD+WWr+qjQ6r7fqzrUfuutt45cLhdHH310wfKUUrRu3TqaN28ey5Ytyy9/66234uijj46NN944iouLo3Xr1rH11lvH8OHDY/r06St9bitKKcWoUaNi7733jpYtW0ZxcXF06dIlDj/88GqPRnnxxRfjoIMOyv/779KlS3z/+9+Pjz76qMq2lecTGTlyZLWPXd1ruvxHbT777LM47bTTon379lFUVBRbbLFF/OUvf6nyGF27do2IiGeffbZgbvu4DlDrEgDfKhGRVvbj/9JLL00RkQ444ID8spNPPjlFRCouLk777bdfOuyww1KrVq1SRKS+ffumL774ouA+DjvssBQRqVmzZmm//fZLQ4YMSbvssksqKytLu+22W8G2Q4cOTRGRRo8enVJKadKkSWno0KGpSZMmKSLS0KFD81/nnHPOSm+XUkqnnnpqioh00003Vfvczj///BQR6Yorrqh2eaNGjVK/fv3SYYcdlnr06JEiInXr1i3NmDEj6yXN23fffVNEpOuuu67KuoqKitSlS5cUEem5557LL1+6dGnacccdU0SkVq1apQMPPDAdfvjhaeedd06NGzdOQ4cOXe3HX5mf/vSnKSLSL37xizR9+vRUUlKSmjZtmv7f//t/BdsVFRVVOzf++c9/phYtWqSISL169UqHHHJI2mWXXVKDBg1S/fr101133VXlNsOHD8+/rgMHDkyHH354ateuXerSpUs68MADq7x/KaW04447puLi4rTDDjukQw89NA0aNCi1b98+RUTafPPN09y5c/Pb3njjjWngwIH592n5ufLAAw/kt4uItNFGG+W/X7hwYSorK0slJSUF91dp2bJlqUOHDql+/frp448/zi//+OOPU+/evVNEpHbt2qX99tsv7bvvvqmsrCxFRBo2bFjW25B38803p4hIQ4YMSaWlpalr167piCOOSN/5znfSo48+mlJK6YEHHsi/H1tvvXU67LDD0o477phyuVxq3LhxevbZZ/P39+GHH6Z69eqlzp07p4qKiiqPN2vWrFRUVJRatmyZFi9enF++0UYbrZX3e6ONNkpFRUVpwYIF+WWffvppyuVyKSJSx44dC7Z/4403UkSkQYMG5Ze98sorqbi4OEVE6t27dzr88MPT/vvvnzbbbLNq58rKLF26NA0ePDg/9/bYY480ZMiQ1K9fv9S4ceN00EEHFWx/2223pfr166eISP369UtDhgxJPXv2TBGR2rZtmyZNmlSwfeW/pZtvvrnax6/uNR09enSKiHTQQQelnj17pg4dOqTBgwenPfbYI//YN954Y377Bx54IB166KH5MSw/t5ffDqA2CAgA3zIrCwgVFRWpb9++KSLShRdemFJK6d57700RkTp06JDefvvt/LazZs1K/fv3TxFRsGP/3nvv5XfYPvnkk4L7X7BgQfrnP/9ZsKy6EJDSyndsVnW7559/PkVE2nPPPat9bp07d0716tVLH374YX75X//61xQRaYsttkhTpkwp2P7iiy9OEZGOOOKIlY5jRXfeeWd+R2RFzz33XIqI1KVLl4KdvH/84x8pItL2229fsAOWUkqzZ89Or7zyymo//sosHxBSSunss89OEZHOPffcgu2qCwizZ89O7du3T/Xr10+33357wbp//etfqUWLFqlp06Zp5syZ+eWV78UGG2yQ3nzzzfzyL774Ir/TX937/vjjj6dZs2YVLFu4cGE+Yv3sZz8rWFe5Y7aqyLJiQEgppRNPPDFFRLr11lurbP/000+niEj77LNPwfL99tsvRUQ666yz0sKFC/PLZ8yYkbbbbrsUEelvf/vbSsexvMqAUBkeli5dWrB+6tSpqUmTJqlp06bpqaeeKlj3t7/9LTVs2DB16tQpLVq0KL98wIABVeJUpZtuuilFRDr11FMLllf376wm7/exxx5b5f28//778+EnIgr+fV177bUpItJvfvObKvfx29/+tsr4J02alD766KMqy6vzi1/8IkVE2myzzdJ7771XsG7WrFlpzJgx+e8/+OCDVFJSkurXr58eeuih/PJly5blA9h2221XcB9fJSBURqPl588DDzyQIiJ17ty54DZTp05NEVElugLUNgEB4FtmxYCwdOnS9Pbbb6fjjjsuRUQqKipK77zzTkoppV133TVFRLrhhhuq3M+ECRNSLpdLTZs2ze/4vvTSSyki0sEHH7xaY1mbAaHyL/wrRoKUUnr22WdTRKQBAwYULN9qq61SRBTs5C5/f1tvvXWqX79+lb/Ur8z8+fNTs2bNUi6Xq7LzUrkTXBlnKt19990pItLw4cNX6zFqYsWA8PHHH6fGjRunxo0bF/yVvbqAcNVVV1UJRcu78sorU0SkK6+8Mr+svLy84PGWN3ny5FSvXr01+qvy/PnzU4MGDdI222xTsLymAaHydgMHDqyy/fHHH58iIt122235ZePHj89HnmXLllW5zWuvvZYiIh144IGr9XwqA0Lr1q2rHMGTUkpnnXVWioj0u9/9rtrbn3nmmSki0v3331/lPk855ZQq2++xxx4pItLzzz9fsLy6f2c1eb//8pe/pIhIP/3pT6uMsXJ+L/+X80MOOSRFRHr55ZfzyyqP3nn99derfdzVsWjRotS8efMUEWncuHGZ21dGwiOPPLLKuoULF6YOHTqkiEgvvPBCfvlXCQilpaVVwmpKKW2xxRYpItLUqVPzywQEoK5yDgSAb6nKz9Q2aNAgevbsGSNHjoxmzZrFqFGjolu3brFkyZIYN25cRESUl5dXuX3v3r2jd+/eMW/evHj99dcj4ssT1jVp0iQee+yx+M1vflPtZ4jX5fM56qijoqKiosq5Fu64446IiILPYs+cOTMmTJgQPXr0iC222KLa++vXr18sW7YsXn311dUaQ0lJSRxyyCGRUoo777wzv3zx4sVxzz33RETVqy9svfXWUa9evbj55pvjxhtvXKPzLtRUmzZt4vTTT4/58+fHr3/961Vu++STT0ZExCGHHFLt+l122SUiIl5++eX8srFjx0bEl+d6WFHPnj1j6623Xunjffjhh3H99dfH8OHD44QTTojjjjsuTjvttGjUqFFMmTJllWNdXbvuumt07NgxnnnmmZg5c2Z++cKFC+O+++6LJk2axHe/+9388srX4OCDD4569ar+6lR5ToTlX4PVsddee1V7ItCavOaHHHJIFBcXx7333htLlizJL//www/j2WefjS5dukS/fv0yx1STx95tt90iIgrOaTFmzJjYdNNN48ADD4yioqL8upRSPPfcc1FaWlpwPpJtt902IiJOP/30GDNmTCxdujRzrCt65ZVXYtasWbHVVlvFjjvumLn9888/HxHV/3wrKirKz9/K7b6qbbfdttpLt/bs2TMiYo3O8wBQWwQEgG+poUOHxtChQ+P444+Ps846K2666aZ4//338ztOn376aSxevDhatWoVTZo0qfY+Kk9O9+GHH0ZERGlpadx4441RVFQU5513Xmy44YbRq1evOPXUU/M7letS5Y5AZTCI+N/Oe3FxccFO0X//+9+IiJgyZUrBScqW//rDH/4QERGffPLJao+hMhAsP4bHH388Pv/889h+++2jV69eBdv37NkzLr/88pg/f36cfPLJ0aZNm9hqq63i7LPPjjfeeGPNXoA1cO6550aTJk3iuuuuixkzZqx0u8rXqV+/ftW+Rttvv31EFL5GlTtCnTp1qvY+O3fuXO3yK6+8Mrp27RqnnXZaXHPNNXHzzTfHLbfcErfcckvMnz8/5s6dW5OnWkW9evXiyCOPjKVLl8bdd9+dX/7oo4/GnDlz4qCDDiqY85WvwYUXXrjSuTJv3rw1micRK38dKh9vww03rPaxKndsl3+80tLSOOCAA+LTTz+Nv//97/nlo0aNioqKijjqqKNWesLE6h57Td7vjTfeODp37hzjxo2LhQsXxmeffRZvvvlm7LHHHlFcXBw77bRTPPvssxHx5YkSP/nkk+jfv3/Ur18/fx/nnntu7L777jF27NjYY489okWLFvGd73wnrrnmmpg9e/ZqvJr/O/nr6l51ozJwLn+SzeWt+PPtq+rYsWO1y5s1axYREYsWLVorjwOwLjWo7QEAUDtWdhbxNVHdDsmRRx4Ze+21Vzz00EPx5JNPxrPPPhs33HBD3HDDDXH22WfHFVdc8ZUfd2U222yz6NOnT7z22msxefLk6NWrV/ztb3+Lzz//PAYPHhylpaX5bSsqKiIiol27djFw4MBV3u9GG2202mPYY489YsMNN4xJkybFq6++Gttuu23+6gsrHn1Q6ZxzzonDDz88HnzwwXjqqafi+eefj6uuuiquvvrquOqqq+Kss85a7cdfXa1bt45hw4bFr3/96xgxYkRcc8011W5X+ToddthhKw1JEfGVLwc4bty4OOecc6KsrCyuueaa2H333aNdu3b5q1V06NBhrf6F9uijj47f/OY3ceedd8YZZ5wREf+LPiv+RbryNejfv/9avSRkcXFxtcsrH2/o0KGrvP2Kf2U/+uij45577ok777wzDjjggIhY+XNamZq+37vttlvcdtttMW7cuPj8888jpZS/MsPuu+8ezz77bLzzzjv5IxEqj1qoVFpaGv/4xz9i7Nix8cgjj8SYMWPiH//4Rzz11FMxYsSIeP7556NHjx6r9RzWltUJLiuqfP2qU93RKwBfNwICANVq2bJlNGrUKD755JP44osvqt2ZWP4vpctr3bp1nHTSSXHSSSdFSimeeOKJOOKII+LKK6+ME044ITbffPN1Nu7y8vIYP3583HHHHfHzn/+82o8vRPzvr4GtWrVaKzGlUr169aK8vDwuv/zyuP3226N79+7x6KOPRoMGDWLIkCErvV2nTp3ijDPOiDPOOCOWLl0ad911Vxx//PFx3nnnxbHHHhstWrRYa2OsdO6558Yf//jH+NOf/rTSSwB27NgxJk+eHD/60Y/yh5lnad++ffz3v/+NadOmVTniIqLqZUIjIh544IGIiLj00kur7DgvWLBglUdJ1ETv3r1jiy22iHHjxsV7770XLVq0iMcffzxat24d3/nOdwq2rZwrBx98cJxzzjlrdRzV6dixY7z77rtxxRVXVHvI+8rsu+++scEGG8TDDz8c8+bNiw8++CBef/316NOnT2y22War/dhr+n5H/C8gjBkzJj7//POIiIKA8LOf/SzGjBmTDwjVXfYxl8tF//79o3///hHx5ceMhg8fHqNGjYoLL7ww/vrXv65yDJVHvLz77rurNeYOHTrE5MmT4/3336/2Z1J1P98aNWoUEV9eenVFy5YtW+vzFKCukUIBqFbDhg1jp512ioiock6BiC8PRZ4wYUI0bdp0lZ9pz+Vysc8++8SgQYMiIqpcw746lb+k1+Rz0EceeWTUq1cvRo0aFXPmzIlHHnkkNthgg9h3330LtuvYsWNssskmMXHixHj77bfX+HFWpTJW3HXXXXH33XfHokWLYuDAgdG6devVun2DBg3i6KOPju233z4WL1681j77v6KWLVvGGWecEQsXLoxf/epX1W6z9957R8T/dvBXR+Vn7e+7774q6955550YP358leWVO53VHeZ9zz33REqpyvKvMk8i/vdX+TvvvDPuvffeWLx4cRxxxBHRoEHh31dq8hp8FTV9vIYNG8bgwYNj/vz58eCDD67x0Qdf5bErg0BlJNh8883z832nnXaKoqKiGD16dDz33HPRrFmz1YoTbdq0iUsuuSQivvx5k2XbbbeN5s2bx4QJE1brfBSV53MYNWpUlXXLn7ekcruIL+NYRFT7M2P06NEF55/4Kr7q3AZYVwQEAFaq8tDuSy65JN5777388rlz58awYcMipRSnnHJK/lDs8ePHx/333x+LFy8uuJ/PPvssXnrppYhY+efil9ehQ4eIiJg8efIaj7lDhw6xxx57xDvvvBPnn39+LFy4MAYPHhwNGzassu1FF10UFRUVceihh+ZPBLm8Tz/9NG688cY1HsOWW24ZW221VcyYMSMuvPDCiFj5xxdGjx4dTz/9dJVDn6dOnRqTJk2KXC5XsFP9+9//PjbZZJO44IIL1nhc1TnnnHOitLQ0brrppmp3fk455ZRo06ZNXH755fGnP/2pyjiXLl0aTzzxRMEO3imnnBIRX57TYOLEifnlCxYsiDPPPLPaw7wrTyT35z//uWAcEydOXOnREV9lnkRE/rwAd9555yp3tnfcccfYe++9Y+zYsXH66afHnDlzqmwzYcKEgnMPfBXnnHNOlJSUxA9/+MO4//77q6xftGhR3HvvvfF///d/VdZVxqs77rgjRo0alT/fw+qqyfsd8eV5Bzp27BgvvvhivPnmmwVHGFSeB+H++++PTz75JPr161dw/oOIiOuvvz6mTp1aZTyPP/54RKzez42ioqL4wQ9+EBERJ554Yrz//vsF62fPnp0/F0PlNiUlJXHXXXfFY489ll9eUVERP/7xj+PDDz+MbbfdtuDkk7vuumtERNx+++35IxQivvz3euaZZ2aOcXW1atUqGjZsGO+++24sW7Zsrd0vwFdWm5eAAGD9ixUu45il8vKDJSUladCgQWnw4MGpdevWKSLSTjvtVHAZusprmpeVlaUBAwak8vLyNGjQoNSsWbMUEemAAw4ouO+VXcbxiiuuSBGR2rZtm4YMGZJOPPHEdP7552ferlLlZeUqv1a8fN3yfvzjH6eISPXq1UvbbLNNGjx4cDrssMNSnz59Uv369VNZWdlqv1bL++1vf5t//NLS0jR//vxqt6u8bF7r1q3TPvvsk8rLy9N3vvOd/CUVzzjjjILtKy8jt6pLF65oxcs4ruiiiy4qeL1W9OKLL6ZWrVqliEidOnVK++67bzrqqKPSnnvumb9s3gMPPFBwm+HDh+cvC7rPPvukww8/PLVv3z5ttNFG6YADDkgRkcaOHZvf/pNPPknt2rVLEZG6du2aDj/88LTXXnulhg0bpsGDB6/00p69e/fOX2LxuOOOSyeeeGJ66KGH8uujmss4Lq/yUqURkbp167bS7T7++OPUp0+fFBGpefPmaffdd09HHXVUGjRoUOrUqVOKiHTWWWet9PbLq7zk4vKXPVzRgw8+mBo3bpwiInXv3j0dcMABaciQIWmXXXZJTZo0SRGRxo8fX+V2FRUV+dcqqrl06fJW9prW5P1O6X+X74yIdM899xSsq5yDEZEuu+yyKretvKTqZpttlg499NB0xBFH5JcVFxcXXEpxVZYsWZIOPvjgFBGpUaNGacCAAenII49M/fv3T40bN04HHXRQwfa33nprqlevXsrlcql///7pyCOPTL169cr//Jk0aVKVxzj22GPzP+cOOOCANGDAgNSkSZOVztOsy42u7OdZ5b+TzTffPB1zzDHpxBNPTH/5y19W63UAWFcEBIBvmTUNCCl9+Uv2zjvvnJo2bZqKi4vT5ptvni699NIqO8XTp09Pv/zlL9Oee+6ZOnbsmBo1apTatm2b+vXrl/7yl7+kxYsXF2y/sl+clyxZkn7yk5+kbt26pYYNG1bZCcwKCLNnz07FxcX521VUVKzy+T377LNp8ODBqUOHDqlhw4apZcuWqXfv3mnYsGHp2WefXe3XaXkfffRRql+/foqIdPzxx690uylTpqSf/OQnqV+/fql9+/apUaNGacMNN0wDBgxI9913X5Wxr4uA8Pnnn6eysrJVzo3p06en8847L22++eapcePGqXHjxqlbt27poIMOSiNHjkxz584t2L6ioiJdf/31acstt0xFRUWpTZs2aejQoWn69Olpr732ShGR/vOf/xTcZtq0aemoo45KG264YSouLk6bbrppuuyyy9LSpUtXurM7ZcqUdPDBB6eWLVumevXqVdkxzwoIN9xwQ/55X3zxxSvdLqWUFixYkK699tq08847p7KystSoUaPUqVOntNtuu6Xf/OY3adq0aau8faXVCQgppfTOO++k73//+6lHjx6puLg4NWvWLPXq1SsNGTIk/fWvf02LFi2q9nYXXHBB/jmtaodzZa9pSmv+fqeU0o033pgiIuVyuTRz5syCdZU70RGRxo0bV+W2Dz/8cDrhhBPS5ptvnpo3b54aN26cevbsmU466aQq8yTLsmXL0siRI9Ouu+6aysrKUlFRUerSpUs6/PDDq/2ZMXbs2HTAAQekli1bpoYNG6bOnTun0047Lf3f//1ftfe/aNGi9KMf/Sh16tQpNWrUKHXr1i398pe/XOk8rWlA+Pjjj9MxxxyT2rVrl/9Zsib/7gHWhVxK1XyoEABgHZg3b1507do1Fi5cGLNmzapyKDsAUHc5BwIAsNZNmjQp5s+fX7Bszpw5cfLJJ8cnn3wSQ4YMEQ8A4GvGEQgAwFp36qmnxu233x7bbrtttG/fPj755JMYP358fPbZZ7HxxhvHuHHjVvuqFABA3dAgexMAgDVzyCGHxIwZM+LVV1/NX1Kva9eucdJJJ8V5550XLVu2rOURAgBryhEIAAAAQCbnQAAAAAAyCQgAAABAJudAqEMqKirio48+imbNmkUul6vt4QAAAPANl1KKuXPnRocOHaJevVUfYyAg1CEfffRRdOrUqbaHAQAAwLfMtGnTomPHjqvcRkCoQ5o1axYRX75xpaWltTwaAAAAvunmzJkTnTp1yu+ProqAUIdUfmyhtLRUQAAAAGC9WZ2P0TuJIgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyNSgtgdAVQPP+nU0aFRc28MAAACgBp6/4aLaHsI64QgEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADJ96wLCmDFjIpfLxaxZs1a5XZcuXeLqq69eL2MCAACAuu5bFxB23nnnmD59epSVlUVExMiRI6N58+ZVtvvXv/4VJ5988noeHQAAANRNDWp7AOtbo0aNol27dpnbtW7dej2MBgAAAL4e6uQRCLvvvnsMGzYshg0bFmVlZdGqVau46KKLIqUUERGff/55HHvssdGiRYto3Lhx7LvvvjFlypT87d9///044IADokWLFtGkSZPYfPPN4/HHH4+Iwo8wjBkzJo4//viYPXt25HK5yOVycckll0RE4UcYjjrqqDjiiCMKxrhkyZJo1apV3HrrrRERUVFRESNGjIiuXbtGSUlJbLXVVnHvvfeu41cKAAAA1o86ewTCLbfcEieeeGK8/PLL8corr8TJJ58cnTt3ju9973tx3HHHxZQpU+Lhhx+O0tLSOP/882O//faLiRMnRsOGDeP000+PxYsXx3PPPRdNmjSJiRMnRtOmTas8xs477xxXX311XHzxxTF58uSIiGq3Ky8vj8GDB8e8efPy65944omYP39+fPe7342IiBEjRsTtt98e119/ffTo0SOee+65OProo6N169ax2267VfscFy1aFIsWLcp/P2fOnK/8ugEAAMC6UGcDQqdOneKqq66KXC4XvXr1ijfffDOuuuqq2H333ePhhx+OsWPHxs477xwREXfccUd06tQpHnzwwRg8eHB88MEHceihh8aWW24ZEREbb7xxtY/RqFGjKCsri1wut8qPNQwcODCaNGkSDzzwQBxzzDEREXHnnXfGgQceGM2aNYtFixbFr371q3j66aejb9+++cd84YUX4oYbblhpQBgxYkT87Gc/q/FrBAAAAOtLnfwIQ0TETjvtFLlcLv993759Y8qUKTFx4sRo0KBB7Ljjjvl1LVu2jF69esWkSZMiIuLMM8+MX/7yl9GvX7/46U9/Gm+88cZXGkuDBg3i8MMPjzvuuCMiIr744ot46KGHory8PCIi3nnnnZg/f37svffe0bRp0/zXrbfeGu++++5K7/eCCy6I2bNn57+mTZv2lcYJAAAA60qdPQLhqzjppJNi4MCB8dhjj8WTTz4ZI0aMiCuuuCLOOOOMGt9neXl57LbbbjFz5sx46qmnoqSkJPbZZ5+IiJg3b15ERDz22GOx4YYbFtyuqKhopfdZVFS0yvUAAABQV9TZIxBeeumlgu/HjRsXPXr0iM022yyWLl1asP7TTz+NyZMnx2abbZZf1qlTpzj11FPj/vvvj3POOSduvPHGah+nUaNGsWzZsszx7LzzztGpU6e4++6744477ojBgwdHw4YNIyJis802i6Kiovjggw+ie/fuBV+dOnWqydMHAACAOqXOHoHwwQcfxNlnnx2nnHJKvPbaa/G73/0urrjiiujRo0ccdNBB8b3vfS9uuOGGaNasWfzoRz+KDTfcMA466KCIiBg+fHjsu+++0bNnz/j8889j9OjRsemmm1b7OF26dIl58+bFM888E1tttVU0btw4GjduXO22Rx11VFx//fXx9ttvx+jRo/PLmzVrFj/84Q/jBz/4QVRUVET//v1j9uzZMXbs2CgtLY2hQ4eu/RcIAAAA1qM6ewTCscceGwsWLIgddtghTj/99DjrrLPi5JNPjoiIm2++ObbddtvYf//9o2/fvpFSiscffzx/RMCyZcvi9NNPj0033TT22Wef6NmzZ/zxj3+s9nF23nnnOPXUU+OII46I1q1bx+WXX77SMZWXl8fEiRNjww03jH79+hWs+8UvfhEXXXRRjBgxIv+4jz32WHTt2nUtvSIAAABQe3IppVTbg1jR7rvvHltvvXVcffXVtT2U9WrOnDlRVlYWOx3342jQqLi2hwMAAEANPH/DRbU9hNVWuR86e/bsKC0tXeW2dfYIBAAAAKDuEBAAAACATHXyJIpjxoyp7SEAAAAAy3EEAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGSqUUA44YQTYu7cuVWWf/HFF3HCCSd85UEBAAAAdUuNAsItt9wSCxYsqLJ8wYIFceutt37lQQEAAAB1S4M12XjOnDmRUoqUUsydOzeKi4vz65YtWxaPP/54tGnTZq0P8tvmiWvOj9LS0toeBgAAAOStUUBo3rx55HK5yOVy0bNnzyrrc7lc/OxnP1trgwMAAADqhjUKCKNHj46UUuy5555x3333xQYbbJBf16hRo9hoo42iQ4cOa32QAAAAQO1ao4Cw2267RUTE1KlTo1OnTlGvnos4AAAAwLfBGgWEShtttFHMmjUrXn755Zg5c2ZUVFQUrD/22GPXyuAAAACAuqFGAeGRRx6J8vLymDdvXpSWlkYul8uvy+VyAgIAAAB8w9ToMwjnnHNOnHDCCTFv3ryYNWtWfP755/mvzz77bG2PEQAAAKhlNQoIH374YZx55pnRuHHjtT0eAAAAoA6qUUAYOHBgvPLKK2t7LAAAAEAdVaNzIAwaNCjOPffcmDhxYmy55ZbRsGHDgvUHHnjgWhkcAAAAUDfkUkppTW+0qss35nK5WLZs2Vca1LfVnDlzoqysLGbPnh2lpaW1PRwAAAC+4dZkP7RGRyCseNlGAAAA4JutRudAWN7ChQvXxjgAAACAOqxGAWHZsmXxi1/8IjbccMNo2rRpvPfeexERcdFFF8Wf//zntTpAAAAAoPbVKCBceumlMXLkyLj88sujUaNG+eVbbLFF3HTTTWttcAAAAEDdUKOAcOutt8af/vSnKC8vj/r16+eXb7XVVvGf//xnrQ0OAAAAqBtqFBA+/PDD6N69e5XlFRUVsWTJkq88KAAAAKBuqVFA2GyzzeL555+vsvzee++NPn36fOVBAQAAAHVLjS7jePHFF8fQoUPjww8/jIqKirj//vtj8uTJceutt8ajjz66tscIAAAA1LIaHYFw0EEHxSOPPBJPP/10NGnSJC6++OKYNGlSPPLII7H33nuv7TECAAAAtSyXUkq1PQi+NGfOnCgrK4vZs2dHaWlpbQ8HAACAb7g12Q+t0UcYljdv3ryoqKgoWGbnFwAAAL5ZavQRhqlTp8agQYOiSZMmUVZWFi1atIgWLVpE8+bNo0WLFmt7jAAAAEAtq9ERCEcffXSklOIvf/lLtG3bNnK53NoeFwAAAFCH1CggTJgwIV599dXo1avX2h4PAAAAUAfV6CMM22+/fUybNm1tjwUAAACoo2p0BMJNN90Up556anz44YexxRZbRMOGDQvW9+7de60MDgAAAKgbahQQ/t//+3/x7rvvxvHHH59flsvlIqUUuVwuli1bttYGCAAAANS+GgWEE044Ifr06ROjRo1yEkUAAAD4FqhRQHj//ffj4Ycfju7du6/t8QAAAAB1UI1OorjnnnvGhAkT1vZYAAAAgDqqRkcgHHDAAfGDH/wg3nzzzdhyyy2rnETxwAMPXCuDAwAAAOqGXEopremN6tVb+YELTqJYc3PmzImysrKYPXt2lJaW1vZwAAAA+IZbk/3QGh2BUFFRUaOBAQAAAF9PNToHAgAAAPDtstpHIFx77bVx8sknR3FxcVx77bWr3PbMM8/8ygMDAAAA6o7VPgdC165d45VXXomWLVtG165dV36HuVy89957a22A3ybOgQAAAMD6tE7OgTB16tRq/xsAAAD45qvRORB+/vOfx/z586ssX7BgQfz85z//yoMCAAAA6pYaXcaxfv36MX369GjTpk3B8k8//TTatGnjMo415CMMAAAArE9rsh9aoyMQUkqRy+WqLJ8wYUJssMEGNblLAAAAoA5b7XMgRES0aNEicrlc5HK56NmzZ0FEWLZsWcybNy9OPfXUtT5IAAAAoHatUUC4+uqrI6UUJ5xwQvzsZz+LsrKy/LpGjRpFly5dom/fvmt9kAAAAEDtWqOAMHTo0Ij48pKOO++8czRs2HCdDAoAAACoW9YoIFTabbfdoqKiIt5+++2YOXNmVFRUFKzfdddd18rgAAAAgLqhRgFh3LhxcdRRR8X7778fK17EIZfLuQoDAAAAfMPUKCCceuqpsd1228Vjjz0W7du3r/aKDAAAAMA3R40CwpQpU+Lee++N7t27r+3xAAAAAHVQvZrcaMcdd4x33nlnbY8FAAAAqKNqdATCGWecEeecc07MmDEjttxyyypXY+jdu/daGRwAAABQN+TSimdBXA316lU9cCGXy0VKyUkUv4I5c+ZEWVlZzJ49O0pLS2t7OAAAAHzDrcl+aI2OQJg6dWqNBgYAAAB8PdUoIGy00UZrexwAAABAHVajkyhGRNx2223Rr1+/6NChQ7z//vsREXH11VfHQw89tNYGBwAAANQNNQoI1113XZx99tmx3377xaxZs/LnPGjevHlcffXVa3N8AAAAQB1Qo4Dwu9/9Lm688ca48MILo379+vnl2223Xbz55ptrbXAAAABA3VCjgDB16tTo06dPleVFRUXxxRdffOVBAQAAAHVLjQJC165d4/XXX6+y/O9//3tsuummX3VMAAAAQB1To6swnH322XH66afHwoULI6UUL7/8cowaNSpGjBgRN91009oeIwAAAFDLahQQTjrppCgpKYmf/OQnMX/+/DjqqKNiww03jGuuuSaGDBmytscIAAAA1LIaBYQFCxbEd7/73SgvL4/58+fHW2+9FWPHjo2OHTuu7fEBAAAAdUCNzoFw0EEHxa233hoREYsXL44DDzwwrrzyyjj44IPjuuuuW6sDBAAAAGpfjY5AeO211+Kqq66KiIh777032rZtG+PHj4/77rsvLr744jjttNPW6iC/bQ6+95Jo0LiotocBAADwrfLkkBG1PYQ6rUZHIMyfPz+aNWsWERFPPvlkHHLIIVGvXr3Yaaed4v3331+rAwQAAABqX40CQvfu3ePBBx+MadOmxRNPPBHf+c53IiJi5syZUVpaulYHCAAAANS+GgWEiy++OH74wx9Gly5dYscdd4y+fftGxJdHI/Tp02etDhAAAACofTU6B8Jhhx0W/fv3j+nTp8dWW22VXz5gwID47ne/u9YGBwAAANQNNQoIERHt2rWLdu3aFSzbYYcdvvKAAAAAgLqnRh9hAAAAAL5dBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCCsxCWXXBJbb711bQ8DAAAA6gQBISJyuVw8+OCDBct++MMfxjPPPFM7AwIAAIA6pkFtD6Cuatq0aTRt2rS2hwEAAAB1Qq0egbD77rvHmWeeGeedd15ssMEG0a5du7jkkkvy62fNmhUnnXRStG7dOkpLS2PPPfeMCRMmFNzHL3/5y2jTpk00a9YsTjrppPjRj35U8NGDf/3rX7H33ntHq1atoqysLHbbbbd47bXX8uu7dOkSERHf/e53I5fL5b9f/iMMTz75ZBQXF8esWbMKHvuss86KPffcM//9Cy+8ELvsskuUlJREp06d4swzz4wvvvjiK79OAAAAUNtq/SMMt9xySzRp0iReeumluPzyy+PnP/95PPXUUxERMXjw4Jg5c2b87W9/i1dffTW22WabGDBgQHz22WcREXHHHXfEpZdeGr/+9a/j1Vdfjc6dO8d1111XcP9z586NoUOHxgsvvBDjxo2LHj16xH777Rdz586NiC8DQ0TEzTffHNOnT89/v7wBAwZE8+bN47777ssvW7ZsWdx9991RXl4eERHvvvtu7LPPPnHooYfGG2+8EXfffXe88MILMWzYsJU+90WLFsWcOXMKvgAAAKAuyqWUUm09+O677x7Lli2L559/Pr9shx12iD333DP233//GDRoUMycOTOKiory67t37x7nnXdenHzyybHTTjvFdtttF7///e/z6/v37x/z5s2L119/vdrHrKioiObNm8edd94Z+++/f0R8eQ6EBx54IA4++OD8dpdcckk8+OCD+fsZPnx4vPnmm/nzIjz55JNx4IEHxowZM6J58+Zx0kknRf369eOGG27I38cLL7wQu+22W3zxxRdRXFxcZSyXXHJJ/OxnP6uyfI8//yAaNC6qshwAAIB158khI2p7COvdnDlzoqysLGbPnh2lpaWr3LbWj0Do3bt3wfft27ePmTNnxoQJE2LevHnRsmXL/PkImjZtGlOnTo133303IiImT54cO+ywQ8HtV/z+448/ju9973vRo0ePKCsri9LS0pg3b1588MEHazTO8vLyGDNmTHz00UcR8eXRD4MGDYrmzZtHRMSECRNi5MiRBWMdOHBgVFRUxNSpU6u9zwsuuCBmz56d/5o2bdoajQkAAADWl1o/iWLDhg0Lvs/lclFRURHz5s2L9u3bx5gxY6rcpnKnfXUMHTo0Pv3007jmmmtio402iqKioujbt28sXrx4jca5/fbbR7du3eKuu+6K0047LR544IEYOXJkfv28efPilFNOiTPPPLPKbTt37lztfRYVFRUcXQEAAAB1Va0HhJXZZpttYsaMGdGgQYP8iQ1X1KtXr/jXv/4Vxx57bH7ZiucwGDt2bPzxj3+M/fbbLyIipk2bFp988knBNg0bNoxly5Zljqm8vDzuuOOO6NixY9SrVy8GDRpUMN6JEydG9+7dV/cpAgAAwNdGrX+EYWX22muv6Nu3bxx88MHx5JNPxn//+9/45z//GRdeeGG88sorERFxxhlnxJ///Oe45ZZbYsqUKfHLX/4y3njjjcjlcvn76dGjR9x2220xadKkeOmll6K8vDxKSkoKHqtLly7xzDPPxIwZM+Lzzz9f6ZjKy8vjtddei0svvTQOO+ywgqMHzj///PjnP/8Zw4YNi9dffz2mTJkSDz300CpPoggAAABfF3U2IORyuXj88cdj1113jeOPPz569uwZQ4YMiffffz/atm0bEV/u0F9wwQXxwx/+MLbZZpuYOnVqHHfccQUnLPzzn/8cn3/+eWyzzTZxzDHHxJlnnhlt2rQpeKwrrrginnrqqejUqVP06dNnpWPq3r177LDDDvHGG2/kr75QqXfv3vHss8/G22+/Hbvsskv06dMnLr744ujQocNafFUAAACgdtTqVRjWhb333jvatWsXt912W20PZY1Vnv3SVRgAAADWP1dhWPVVGOrsORBWx/z58+P666+PgQMHRv369WPUqFHx9NNPx1NPPVXbQwMAAIBvlK91QKj8mMOll14aCxcujF69esV9990Xe+21V20PDQAAAL5RvtYBoaSkJJ5++unaHgYAAAB849XZkygCAAAAdYeAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACBTg9oeAFU9eNglUVpaWtvDAAAAgDxHIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACCTgAAAAABkEhAAAACATAICAAAAkElAAAAAADIJCAAAAEAmAQEAAADIJCAAAAAAmQQEAAAAIJOAAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJCpQW0PgP9JKUVExJw5c2p5JAAAAHwbVO5/Vu6ProqAUId8+umnERHRqVOnWh4JAAAA3yZz586NsrKyVW4jINQhG2ywQUREfPDBB5lvHFSaM2dOdOrUKaZNmxalpaW1PRy+JswbasK8oSbMG2rCvKEmzJuaSSnF3Llzo0OHDpnbCgh1SL16X56SoqyszIRnjZWWlpo3rDHzhpowb6gJ84aaMG+oCfNmza3uH7CdRBEAAADIJCAAAAAAmQSEOqSoqCh++tOfRlFRUW0Pha8R84aaMG+oCfOGmjBvqAnzhpowb9a9XFqdazUAAAAA32qOQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEhDrkD3/4Q3Tp0iWKi4tjxx13jJdffrm2h8R6MmLEiNh+++2jWbNm0aZNmzj44INj8uTJBdssXLgwTj/99GjZsmU0bdo0Dj300Pj4448Ltvnggw9i0KBB0bhx42jTpk2ce+65sXTp0oJtxowZE9tss00UFRVF9+7dY+TIkev66bEeXHbZZZHL5WL48OH5ZeYMK/Phhx/G0UcfHS1btoySkpLYcsst45VXXsmvTynFxRdfHO3bt4+SkpLYa6+9YsqUKQX38dlnn0V5eXmUlpZG8+bN48QTT4x58+YVbPPGG2/ELrvsEsXFxdGpU6e4/PLL18vzY+1btmxZXHTRRdG1a9coKSmJbt26xS9+8YtY/lzc5g3PPfdcHHDAAdGhQ4fI5XLx4IMPFqxfn3PknnvuiU022SSKi4tjyy23jMcff3ytP1/WjlXNmyVLlsT5558fW265ZTRp0iQ6dOgQxx57bHz00UcF92HerEeJOuGuu+5KjRo1Sn/5y1/Sv//97/S9730vNW/ePH388ce1PTTWg4EDB6abb745vfXWW+n1119P++23X+rcuXOaN29efptTTz01derUKT3zzDPplVdeSTvttFPaeeed8+uXLl2atthii7TXXnul8ePHp8cffzy1atUqXXDBBflt3nvvvdS4ceN09tlnp4kTJ6bf/e53qX79+unvf//7en2+rF0vv/xy6tKlS+rdu3c666yz8svNGarz2WefpY022igdd9xx6aWXXkrvvfdeeuKJJ9I777yT3+ayyy5LZWVl6cEHH0wTJkxIBx54YOratWtasGBBfpt99tknbbXVVmncuHHp+eefT927d09HHnlkfv3s2bNT27ZtU3l5eXrrrbfSqFGjUklJSbrhhhvW6/Nl7bj00ktTy5Yt06OPPpqmTp2a7rnnntS0adN0zTXX5Lcxb3j88cfThRdemO6///4UEemBBx4oWL++5sjYsWNT/fr10+WXX54mTpyYfvKTn6SGDRumN998c52/Bqy5Vc2bWbNmpb322ivdfffd6T//+U968cUX0w477JC23Xbbgvswb9YfAaGO2GGHHdLpp5+e/37ZsmWpQ4cOacSIEbU4KmrLzJkzU0SkZ599NqX05Q/Phg0bpnvuuSe/zaRJk1JEpBdffDGl9OUP33r16qUZM2bkt7nuuutSaWlpWrRoUUoppfPOOy9tvvnmBY91xBFHpIEDB67rp8Q6Mnfu3NSjR4/01FNPpd122y0fEMwZVub8889P/fv3X+n6ioqK1K5du/Sb3/wmv2zWrFmpqKgojRo1KqWU0sSJE1NEpH/961/5bf72t7+lXC6XPvzww5RSSn/84x9TixYt8nOp8rF79eq1tp8S68GgQYPSCSecULDskEMOSeXl5Skl84aqVtwRXJ9z5PDDD0+DBg0qGM+OO+6YTjnllLX6HFn7qgtPK3r55ZdTRKT3338/pWTerG8+wlAHLF68OF599dXYa6+98svq1asXe+21V7z44ou1ODJqy+zZsyMiYoMNNoiIiFdffTWWLFlSMEc22WST6Ny5c36OvPjii7HllltG27Zt89sMHDgw5syZE//+97/z2yx/H5XbmGdfX6effnoMGjSoyvtqzrAyDz/8cGy33XYxePDgaNOmTfTp0yduvPHG/PqpU6fGjBkzCt73srKy2HHHHQvmTvPmzWO77bbLb7PXXntFvXr14qWXXspvs+uuu0ajRo3y2wwcODAmT54cn3/++bp+mqxlO++8czzzzDPx9ttvR0TEhAkT4oUXXoh99903Iswbsq3POeL/Xd9ss2fPjlwuF82bN48I82Z9ExDqgE8++SSWLVtW8Et8RETbtm1jxowZtTQqaktFRUUMHz48+vXrF1tssUVERMyYMSMaNWqU/0FZafk5MmPGjGrnUOW6VW0zZ86cWLBgwbp4OqxDd911V7z22msxYsSIKuvMGVbmvffei+uuuy569OgRTzzxRJx22mlx5plnxi233BIR/3vvV/X/pBkzZkSbNm0K1jdo0CA22GCDNZpffH386Ec/iiFDhsQmm2wSDRs2jD59+sTw4cOjvLw8Iswbsq3PObKybcyhr7+FCxfG+eefH0ceeWSUlpZGhHmzvjWo7QEAhU4//fR466234oUXXqjtoVCHTZs2Lc4666x46qmnori4uLaHw9dIRUVFbLfddvGrX/0qIiL69OkTb731Vlx//fUxdOjQWh4dddVf//rXuOOOO+LOO++MzTffPF5//fUYPnx4dOjQwbwB1oslS5bE4YcfHimluO6662p7ON9ajkCoA1q1ahX169evcnb0jz/+ONq1a1dLo6I2DBs2LB599NEYPXp0dOzYMb+8Xbt2sXjx4pg1a1bB9svPkXbt2lU7hyrXrWqb0tLSKCkpWdtPh3Xo1VdfjZkzZ8Y222wTDRo0iAYNGsSzzz4b1157bTRo0CDatm1rzlCt9u3bx2abbVawbNNNN40PPvggIv733q/q/0nt2rWLmTNnFqxfunRpfPbZZ2s0v/j6OPfcc/NHIWy55ZZxzDHHxA9+8IP8EVDmDVnW5xxZ2Tbm0NdXZTx4//3346mnnsoffRBh3qxvAkId0KhRo9h2223jmWeeyS+rqKiIZ555Jvr27VuLI2N9SSnFsGHD4oEHHoh//OMf0bVr14L12267bTRs2LBgjkyePDk++OCD/Bzp27dvvPnmmwU/QCt/wFbuLPTt27fgPiq3Mc++fgYMGBBvvvlmvP766/mv7bbbLsrLy/P/bc5QnX79+lW5TOzbb78dG220UUREdO3aNdq1a1fwvs+ZMydeeumlgrkza9asePXVV/Pb/OMf/4iKiorYcccd89s899xzsWTJkvw2Tz31VPTq1StatGixzp4f68b8+fOjXr3CXxvr168fFRUVEWHekG19zhH/7/pmqYwHU6ZMiaeffjpatmxZsN68Wc9q+yyOfOmuu+5KRUVFaeTIkWnixInp5JNPTs2bNy84OzrfXKeddloqKytLY8aMSdOnT89/zZ8/P7/Nqaeemjp37pz+8Y9/pFdeeSX17ds39e3bN7++8pJ83/nOd9Lrr7+e/v73v6fWrVtXe0m+c889N02aNCn94Q9/cEm+b5Dlr8KQkjlD9V5++eXUoEGDdOmll6YpU6akO+64IzVu3Djdfvvt+W0uu+yy1Lx58/TQQw+lN954Ix100EHVXmqtT58+6aWXXkovvPBC6tGjR8Els2bNmpXatm2bjjnmmPTWW2+lu+66KzVu3Njl+L6mhg4dmjbccMP8ZRzvv//+1KpVq3TeeefltzFvmDt3bho/fnwaP358ioh05ZVXpvHjx+fPlr++5sjYsWNTgwYN0m9/+9s0adKk9NOf/tTl+OqwVc2bxYsXpwMPPDB17Ngxvf766wW/Jy9/RQXzZv0REOqQ3/3ud6lz586pUaNGaYcddkjjxo2r7SGxnkREtV8333xzfpsFCxak73//+6lFixapcePG6bvf/W6aPn16wf3897//Tfvuu28qKSlJrVq1Suecc05asmRJwTajR49OW2+9dWrUqFHaeOONCx6Dr7cVA4I5w8o88sgjaYsttkhFRUVpk002SX/6058K1ldUVKSLLrootW3bNhUVFaUBAwakyZMnF2zz6aefpiOPPDI1bdo0lZaWpuOPPz7NnTu3YJsJEyak/v37p6KiorThhhumyy67bJ0/N9aNOXPmpLPOOit17tw5FRcXp4033jhdeOGFBb/AmzeMHj262t9nhg4dmlJav3Pkr3/9a+rZs2dq1KhR2nzzzdNjjz22zp43X82q5s3UqVNX+nvy6NGj8/dh3qw/uZRSWn/HOwAAAABfR86BAAAAAGQSEAAAAIBMAgIAAACQSUAAAAAAMgkIAAAAQCYBAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAIBvtf/+97+Ry+Xi9ddfr+2hAECdJiAAAAAAmQQEAKBWVVRUxOWXXx7du3ePoqKi6Ny5c1x66aUREfHmm2/GnnvuGSUlJdGyZcs4+eSTY968efnb7r777jF8+PCC+zv44IPjuOOOy3/fpUuX+NWvfhUnnHBCNGvWLDp37hx/+tOf8uu7du0aERF9+vSJXC4Xu++++zp7rgDwdSYgAAC16oILLojLLrssLrroopg4cWLceeed0bZt2/jiiy9i4MCB0aJFi/jXv/4V99xzTzz99NMxbNiwNX6MK664IrbbbrsYP358fP/734/TTjstJk+eHBERL7/8ckREPP300zF9+vS4//771+rzA4Bviga1PQAA4Ntr7ty5cc0118Tvf//7GDp0aEREdOvWLfr37x833nhjLFy4MG699dZo0qRJRET8/ve/jwMOOCB+/etfR9u2bVf7cfbbb7/4/ve/HxER559/flx11VUxevTo6NWrV7Ru3ToiIlq2bBnt2rVby88QAL45HIEAANSaSZMmxaJFi2LAgAHVrttqq63y8SAiol+/flFRUZE/emB19e7dO//fuVwu2rVrFzNnzqz5wAHgW0hAAABqTUlJyVe6fb169SKlVLBsyZIlVbZr2LBhwfe5XC4qKiq+0mMDwLeNgAAA1JoePXpESUlJPPPMM1XWbbrppjFhwoT44osv8svGjh0b9erVi169ekVEROvWrWP69On59cuWLYu33nprjcbQqFGj/G0BgJUTEACAWlNcXBznn39+nHfeeXHrrbfGu+++G+PGjYs///nPUV5eHsXFxTF06NB46623YvTo0XHGGWfEMccckz//wZ577hmPPfZYPPbYY/Gf//wnTjvttJg1a9YajaFNmzZRUlISf//73+Pjjz+O2bNnr4NnCgBffwICAFCrLrroojjnnHPi4osvjk033TSOOOKImDlzZjRu3DieeOKJ+Oyzz2L77bePww47LAYMGBC///3v87c94YQTYujQoXHsscfGbrvtFhtvvHHssccea/T4DRo0iGuvvTZuuOGG6NChQxx00EFr+ykCwDdCLq34wUEAAACAFTgCAQAAAMgkIAAAAACZBAQAAAAgk4AAAAAAZBIQAAAAgEwCAgAAAJBJQAAAAAAyCQgAAABAJgEBAAAAyCQgAAAAAJkEBAAAACDT/wcY/9xk8FV5wgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize = (12,8))\n",
        "sns.countplot(df['sentiment'],palette='viridis')\n",
        "plt.title(\"Positive Vs. Negative reviews count\", fontsize = 15)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b8549f2",
      "metadata": {
        "id": "9b8549f2"
      },
      "source": [
        "## Upsampling the minority class: (5 points)\n",
        "\n",
        "It is known that Naive bayes is not robust to class imbalance. It could be seen above that the data is little imbalanced. Therefore, class balancing can be done before giving it to the Naive Bayes model for prediction.\n",
        "\n",
        "Feel free to use 'resample' library from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "yHJTAqrW7XMN",
      "metadata": {
        "id": "yHJTAqrW7XMN"
      },
      "outputs": [],
      "source": [
        "## hint: use resample from sklearn.utils\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df[df['sentiment'] == 'positive']\n",
        "df_minority = df[df['sentiment'] == 'negative']\n",
        "\n",
        "negative_upsample = resample(df_minority, replace = True,\n",
        "                        n_samples = df_majority.shape[0],\n",
        "                        random_state = 101)\n",
        "\n",
        "df_upsampled = pd.concat([df_majority, negative_upsample])  # concat two data frames i,e majority class data set and upsampled minority class data set\n",
        "df_upsampled = df_upsampled.sample(frac = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "6a9329bb",
      "metadata": {
        "id": "6a9329bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f4ea86-218c-4060-e54d-558e54de5a55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12474, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "## Just to ensure that upsampling was done successfully, take a look at the shape of the data in\n",
        "## this cell.\n",
        "\n",
        "# print the shape of data set with the help of shape function having \"negative\" as class label\n",
        "df_upsampled[df_upsampled['sentiment'] == 'negative'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8bf6e7",
      "metadata": {
        "id": "6f8bf6e7"
      },
      "source": [
        "### Expected Output :\n",
        "(12474, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "bdea8155",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdea8155",
        "outputId": "1e574904-c4f9-4188-9d44-d176130eab7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12474, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "## Ensure that the same number of data points are present for both 'positive' and 'negative' data\n",
        "\n",
        "# print the shape of data set with the help of shape function having \"positive\" as class label\n",
        "df_upsampled[df_upsampled['sentiment'] == 'positive'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "626f01d5",
      "metadata": {
        "id": "626f01d5"
      },
      "source": [
        "### Expected Output :\n",
        "(12474, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "NoW5z6SzAeP8",
      "metadata": {
        "id": "NoW5z6SzAeP8"
      },
      "outputs": [],
      "source": [
        "## In this cell, we are going to be dividing the data into train and test points\n",
        "## Ensure that you store the upsampled data in a variable called 'df_upsampled'\n",
        "## so that the below operations are performed successfully\n",
        "\n",
        "\n",
        "## Considering 10000 positive and 10000 negative data points\n",
        "negative_data_points_train = df_upsampled[df_upsampled['sentiment']=='negative'].iloc[:10000]\n",
        "positive_data_points_train = df_upsampled[df_upsampled['sentiment']=='positive'].iloc[:10000]\n",
        "\n",
        "## Considering the remaining data points for test\n",
        "negative_data_points_test = df_upsampled[df_upsampled['sentiment']=='negative'].iloc[10000:]\n",
        "positive_data_points_test = df_upsampled[df_upsampled['sentiment']=='positive'].iloc[10000:]\n",
        "\n",
        "## Concatenate the training positive and negative reviews\n",
        "X_train = pd.concat([negative_data_points_train['review'], positive_data_points_train['review']])\n",
        "## Concatenating the training positive and negative outputs\n",
        "y_train = pd.concat([negative_data_points_train['sentiment'], positive_data_points_train['sentiment']])\n",
        "\n",
        "## Concatenating the test positive and negative reviews\n",
        "X_test = pd.concat([negative_data_points_test['review'], positive_data_points_test['review']])\n",
        "## Concatenating the test positive and negative outputs\n",
        "y_test = pd.concat([negative_data_points_test['sentiment'] , positive_data_points_test['sentiment']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "6428047d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6428047d",
        "outputId": "f330f9cf-925b-410b-eade-33498160ea4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "negative    10000\n",
            "positive    10000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## Take a look at the total number of classes and their count using '.value_counts()' for y_train and y_test.\n",
        "## Ensure that there are equal number of positive and negative reviews.\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dfe6517",
      "metadata": {
        "id": "7dfe6517"
      },
      "source": [
        "### Expected Output:\n",
        "negative    10000<br>\n",
        "positive    10000<br>\n",
        "Name: sentiment, dtype: int64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "2beae1d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2beae1d6",
        "outputId": "0c680e43-4a9a-4611-c315-8a7bb27df6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "negative    2474\n",
            "positive    2474\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9163f897",
      "metadata": {
        "id": "9163f897"
      },
      "source": [
        "### Expected Output :\n",
        "negative    2474<br>\n",
        "positive    2474<br>\n",
        "Name: sentiment, dtype: int64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6501699b",
      "metadata": {
        "id": "6501699b"
      },
      "source": [
        "## Q1. Pre-process the reviews: (15 points)\n",
        "\n",
        "We know that a review contains links, punctuation, stopwords and many other words that don't give a lot of meaning for the Naive Bayes model for prediction.\n",
        "\n",
        "In the cell below, one must implement text-preprocessing and remove links, punctuations and stopwords. It is also important to lowercase the letters so that 'Admire' and 'admire' are not treated as different words.\n",
        "\n",
        "In addition to this, perform stemming operation so that similar words are reduced. To know more about stemming, feel free to take a look at this link.\n",
        "\n",
        "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "CirLN9-ddQ1r",
      "metadata": {
        "id": "CirLN9-ddQ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d765e2-c153-44c7-f9a4-e96176c736bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# TASK CELL\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download stopwords if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def clean_review(review):\n",
        "    '''\n",
        "    Input:\n",
        "        review: a string containing a review.\n",
        "    Output:\n",
        "        review_cleaned: a processed review.\n",
        "\n",
        "    '''\n",
        "    # Convert to lowercase\n",
        "    review = review.lower()\n",
        "\n",
        "    # Remove links\n",
        "    review = re.sub(r'http\\S+|www\\S+|https\\S+', '', review, flags=re.MULTILINE)\n",
        "    review = re.sub(r\"[^a-zA-Z]\", \" \", review)\n",
        "    # Remove punctuation\n",
        "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove stopwords\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    review_tokens = review.split()\n",
        "    filtered_words = [word for word in review_tokens if word not in stop_words]\n",
        "\n",
        "    # Apply stemming\n",
        "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "    # Join words back into a single string\n",
        "    review_cleaned = ' '.join(stemmed_words)\n",
        "\n",
        "    return review_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7632fe5",
      "metadata": {
        "id": "a7632fe5"
      },
      "source": [
        "## Q2. Implement a find_occurrence function (5 points):\n",
        "\n",
        "In this function, we find the total occurrence of a word giving information such as label, word and frequency dictionary.\n",
        "\n",
        "Note that this function is used later in the code when we are going to be predicting the output using Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "eb282b81",
      "metadata": {
        "id": "eb282b81"
      },
      "outputs": [],
      "source": [
        "# TASK CELL\n",
        "def find_occurrence(frequency, word, label):\n",
        "    '''\n",
        "    Params:\n",
        "        frequency: a dictionary with the frequency of each pair (or tuple)\n",
        "        word: the word to look up\n",
        "        label: the label corresponding to the word\n",
        "    Return:\n",
        "        n: the number of times the word with its corresponding label appears.\n",
        "    '''\n",
        "    n = frequency.get((word, label), 0)\n",
        "\n",
        "    return n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a2249d",
      "metadata": {
        "id": "29a2249d"
      },
      "source": [
        "### Converting output to numerical format:\n",
        "\n",
        "We have outputs as 'positive' or 'negative'. In the cell below, we convert it to a numerical format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "bcdc2b2c",
      "metadata": {
        "id": "bcdc2b2c"
      },
      "outputs": [],
      "source": [
        "## With the use of mapping function, we replace\n",
        "## the label in the form of string to an integer.\n",
        "\n",
        "output_map = {'positive': 0, 'negative': 1}\n",
        "y_train = y_train.map(output_map)\n",
        "y_test = y_test.map(output_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "3dde0bbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "3dde0bbd",
        "outputId": "d52fb8ed-b337-4e32-a1b6-16475cea4533"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "1    10000\n",
              "0    10000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "## Ensuring that there are equal number of classes on the training data.\n",
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "f2959b85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "f2959b85",
        "outputId": "989548ee-fcd3-492d-83b0-cf0a660fd759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No? Didn\\'t think so! Well, in that case all you have to do is stay far, far away from \"Do You Wanna Know A Secret\", as it\\'s just the umpteenth pointless post-\"Scream\" slasher with absolutely no redeeming value whatsoever. The plot is extremely ridiculous; the characters are insufferably dumb, the gore-factor is negligible and the whole thing is just plain boring! As you can derive from the title already, this film is mainly inspired by \"I Still Know What You Did Last Summer\", as the events take place in a similar setting and the killer\\'s motivations are equally stupid. Why anyone would want to steal ideas from junk like \"IKWYDLS\" is a complete mystery to me, anyway. At least that film could depend on the precious rack of Jennifer Love Hewitt, whereas the girls in this junk are, apart from brainless, also terribly unattractive. One year after the still unsolved murder of her boyfriend, Beth Morgan, her new adulterous lover and four other simple-minded college students go to Florida to spend their Spring Break holiday in a fancy beach house. The killer hasn\\'t made a move all year, but now he follows the posse to Florida and starts butchering them whilst leaving behind the titular message as some sort of business card. You really don\\'t need to be a horror-expert in order to quickly figure out which face hides behind the unspeakably ridiculous mask and the writers\\' attempts to put you on the wrong track are downright embarrassing. Since the plot is so thin, most of the film is purely irrelevant padding, including the sub plots regarding the incompetent Floridian police force and the \\'mysterious\\' FBI inspector who seems to have a personal score to settle. The murder inexplicably happen off screen (don\\'t you hate it when that happens?), there isn\\'t even any gratuitous T&A to enjoy and you better don\\'t get me started on the quality of the dialogs. Suffering through crap like this only makes you realize that the delightful spirit of the 80\\'s slashers is gone for good.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "## Choosing a random review and taking a look at it.\n",
        "X_train.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5e43c9",
      "metadata": {
        "id": "ed5e43c9"
      },
      "source": [
        "From the above cell output, it could be seen that there are a lot of words that don't add a lot of meaning to the text.\n",
        "\n",
        "Therefore, those words would be removed. It also reduces the computation time.\n",
        "\n",
        "Therefore, it is a good practice we are following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "ad3937ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad3937ea",
        "outputId": "573d6bb7-023d-432b-fe59-0cac282149e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "think well case stay far far away wanna know secret umpteenth pointless post scream slasher absolut redeem valu whatsoev plot extrem ridicul charact insuffer dumb gore factor neglig whole thing plain bore deriv titl alreadi film mainli inspir still know last summer event take place similar set killer motiv equal stupid anyon would want steal idea junk like ikwydl complet mysteri anyway least film could depend preciou rack jennif love hewitt wherea girl junk apart brainless also terribl unattract one year still unsolv murder boyfriend beth morgan new adulter lover four simpl mind colleg student go florida spend spring break holiday fanci beach hous killer made move year follow poss florida start butcher whilst leav behind titular messag sort busi card realli need horror expert order quickli figur face hide behind unspeak ridicul mask writer attempt put wrong track downright embarrass sinc plot thin film pure irrelev pad includ sub plot regard incompet floridian polic forc mysteri fbi inspector seem person score settl murder inexplic happen screen hate happen even gratuit enjoy better get start qualiti dialog suffer crap like make realiz delight spirit slasher gone good\n"
          ]
        }
      ],
      "source": [
        "custom_review = X_train.iloc[0]\n",
        "\n",
        "# print cleaned review\n",
        "print(clean_review(custom_review))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e6cc440",
      "metadata": {
        "id": "3e6cc440"
      },
      "source": [
        "We now use this function to pre-process the review and remove words that don't add a lot of meaning in our model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a762960",
      "metadata": {
        "id": "5a762960"
      },
      "source": [
        "## Q3. Implementing review counter function: (5 points)\n",
        "\n",
        "It is now time to implement the count function for the reviews.\n",
        "\n",
        "In this function, we count the occurrence of words and get the probabilities\n",
        "for the words based on the training data.\n",
        "\n",
        "In other words, we get the probability of occurrence of a word, given that the output is 'positive'.\n",
        "\n",
        "Similarly, we also compute the probability of occurence of a word, given that the output is 'negative'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "5de61f77",
      "metadata": {
        "id": "5de61f77"
      },
      "outputs": [],
      "source": [
        "# TASK CELL\n",
        "def review_counter(output_occurrence, reviews, positive_or_negative):\n",
        "    '''\n",
        "    Params:\n",
        "        output_occurrence: a dictionary that will be used to map each pair to its frequency\n",
        "        reviews: a list of reviews\n",
        "        positive_or_negative: a list corresponding to the sentiment of each review (either 0 or 1)\n",
        "    Return:\n",
        "        output: a dictionary mapping each pair to its frequency\n",
        "    '''\n",
        "    ## Steps :\n",
        "    # define the key, which is the word and label tuple\n",
        "    # if the key exists in the dictionary, increment the count\n",
        "    # else, if the key is new, add it to the dictionary and set the count to 1\n",
        "\n",
        "    for label, review in zip(positive_or_negative, reviews):\n",
        "      split_review = clean_review(review).split()\n",
        "      for word in split_review:\n",
        "        # Define the key as the tuple (word, label)\n",
        "        key = (word, label)\n",
        "\n",
        "        # if the key exists in the dictionary, increment the count\n",
        "        if key in output_occurrence:\n",
        "          output_occurrence[key]+=1\n",
        "        else:\n",
        "          output_occurrence[key] = 1\n",
        "\n",
        "    return output_occurrence\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18238223",
      "metadata": {
        "id": "18238223"
      },
      "source": [
        "### Test your function with example reviews:\n",
        "\n",
        "Feel free to run the cell below and understand whether the above function that you have defined is producing the optimum results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "07a4c58a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07a4c58a",
        "outputId": "a26b04a4-8137-427f-94d5-1eeb3b01f797"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('got', 1): 1,\n",
              " ('bore', 1): 2,\n",
              " ('throught', 1): 1,\n",
              " ('moview', 1): 1,\n",
              " ('movi', 0): 2,\n",
              " ('fantast', 0): 1,\n",
              " ('watch', 1): 1,\n",
              " ('complet', 1): 1,\n",
              " ('wast', 1): 1,\n",
              " ('time', 1): 1,\n",
              " ('money', 1): 1,\n",
              " ('enjoy', 0): 1,\n",
              " ('fullest', 0): 1}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Testing your function\n",
        "\n",
        "result = {}\n",
        "reviews = ['got bored throught the moview', 'The movie was fantastic', 'Will not watch it again', 'Was bored, it was a complete waste of time and money', 'Enjoyed the movie to the fullest']\n",
        "ys = [1, 0, 1, 1, 0]\n",
        "review_counter(result,reviews, ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "927f89bb",
      "metadata": {
        "id": "927f89bb"
      },
      "source": [
        "### Expected Output:\n",
        " {('bored', 1): 2, <br>\n",
        " ('complete', 1): 1, <br>\n",
        " ('enjoyed', 0): 1, <br>\n",
        " ('fantastic', 0): 1, <br>\n",
        " ('fullest', 0): 1, <br>\n",
        " ('got', 1): 1, <br>\n",
        " ('money', 1): 1, <br>\n",
        " ('movie', 0): 2, <br>\n",
        " ('moview', 1): 1, <br>\n",
        " ('throught', 1): 1, <br>\n",
        " ('time', 1): 1, <br>\n",
        " ('waste', 1): 1, <br>\n",
        " ('watch', 1): 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "9bc62e13",
      "metadata": {
        "id": "9bc62e13"
      },
      "outputs": [],
      "source": [
        "# Build the freqs dictionary for later uses\n",
        "\n",
        "freqs = review_counter({}, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "0eddf420",
      "metadata": {
        "id": "0eddf420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec5b5a1e-ad30-41be-d662-a02c42f58b6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('think', 1): 3587,\n",
              " ('well', 1): 3450,\n",
              " ('case', 1): 707,\n",
              " ('stay', 1): 509,\n",
              " ('far', 1): 1250,\n",
              " ('away', 1): 1139,\n",
              " ('wanna', 1): 86,\n",
              " ('know', 1): 3131,\n",
              " ('secret', 1): 294,\n",
              " ('umpteenth', 1): 8,\n",
              " ('pointless', 1): 355,\n",
              " ('post', 1): 212,\n",
              " ('scream', 1): 364,\n",
              " ('slasher', 1): 248,\n",
              " ('absolut', 1): 903,\n",
              " ('redeem', 1): 299,\n",
              " ('valu', 1): 509,\n",
              " ('whatsoev', 1): 228,\n",
              " ('plot', 1): 3496,\n",
              " ('extrem', 1): 659,\n",
              " ('ridicul', 1): 747,\n",
              " ('charact', 1): 5690,\n",
              " ('insuffer', 1): 18,\n",
              " ('dumb', 1): 512,\n",
              " ('gore', 1): 558,\n",
              " ('factor', 1): 129,\n",
              " ('neglig', 1): 16,\n",
              " ('whole', 1): 1482,\n",
              " ('thing', 1): 3802,\n",
              " ('plain', 1): 360,\n",
              " ('bore', 1): 1592,\n",
              " ('deriv', 1): 69,\n",
              " ('titl', 1): 793,\n",
              " ('alreadi', 1): 618,\n",
              " ('film', 1): 17873,\n",
              " ('mainli', 1): 146,\n",
              " ('inspir', 1): 210,\n",
              " ('still', 1): 1838,\n",
              " ('last', 1): 1228,\n",
              " ('summer', 1): 127,\n",
              " ('event', 1): 411,\n",
              " ('take', 1): 2554,\n",
              " ('place', 1): 1141,\n",
              " ('similar', 1): 304,\n",
              " ('set', 1): 1607,\n",
              " ('killer', 1): 711,\n",
              " ('motiv', 1): 229,\n",
              " ('equal', 1): 224,\n",
              " ('stupid', 1): 1359,\n",
              " ('anyon', 1): 1152,\n",
              " ('would', 1): 5909,\n",
              " ('want', 1): 2858,\n",
              " ('steal', 1): 242,\n",
              " ('idea', 1): 1377,\n",
              " ('junk', 1): 143,\n",
              " ('like', 1): 9817,\n",
              " ('ikwydl', 1): 3,\n",
              " ('complet', 1): 1441,\n",
              " ('mysteri', 1): 479,\n",
              " ('anyway', 1): 590,\n",
              " ('least', 1): 1554,\n",
              " ('could', 1): 3729,\n",
              " ('depend', 1): 69,\n",
              " ('preciou', 1): 70,\n",
              " ('rack', 1): 27,\n",
              " ('jennif', 1): 84,\n",
              " ('love', 1): 2308,\n",
              " ('hewitt', 1): 9,\n",
              " ('wherea', 1): 55,\n",
              " ('girl', 1): 1661,\n",
              " ('apart', 1): 380,\n",
              " ('brainless', 1): 35,\n",
              " ('also', 1): 2924,\n",
              " ('terribl', 1): 1385,\n",
              " ('unattract', 1): 23,\n",
              " ('one', 1): 10908,\n",
              " ('year', 1): 2224,\n",
              " ('unsolv', 1): 12,\n",
              " ('murder', 1): 730,\n",
              " ('boyfriend', 1): 196,\n",
              " ('beth', 1): 10,\n",
              " ('morgan', 1): 58,\n",
              " ('new', 1): 1363,\n",
              " ('adulter', 1): 14,\n",
              " ('lover', 1): 241,\n",
              " ('four', 1): 381,\n",
              " ('simpl', 1): 280,\n",
              " ('mind', 1): 970,\n",
              " ('colleg', 1): 209,\n",
              " ('student', 1): 345,\n",
              " ('go', 1): 3979,\n",
              " ('florida', 1): 35,\n",
              " ('spend', 1): 431,\n",
              " ('spring', 1): 35,\n",
              " ('break', 1): 479,\n",
              " ('holiday', 1): 79,\n",
              " ('fanci', 1): 74,\n",
              " ('beach', 1): 142,\n",
              " ('hous', 1): 873,\n",
              " ('made', 1): 3511,\n",
              " ('move', 1): 819,\n",
              " ('follow', 1): 811,\n",
              " ('poss', 1): 18,\n",
              " ('start', 1): 1822,\n",
              " ('butcher', 1): 52,\n",
              " ('whilst', 1): 116,\n",
              " ('leav', 1): 870,\n",
              " ('behind', 1): 484,\n",
              " ('titular', 1): 26,\n",
              " ('messag', 1): 338,\n",
              " ('sort', 1): 772,\n",
              " ('busi', 1): 284,\n",
              " ('card', 1): 130,\n",
              " ('realli', 1): 4990,\n",
              " ('need', 1): 1447,\n",
              " ('horror', 1): 1789,\n",
              " ('expert', 1): 84,\n",
              " ('order', 1): 470,\n",
              " ('quickli', 1): 240,\n",
              " ('figur', 1): 506,\n",
              " ('face', 1): 924,\n",
              " ('hide', 1): 183,\n",
              " ('unspeak', 1): 16,\n",
              " ('mask', 1): 178,\n",
              " ('writer', 1): 844,\n",
              " ('attempt', 1): 1077,\n",
              " ('put', 1): 1408,\n",
              " ('wrong', 1): 988,\n",
              " ('track', 1): 278,\n",
              " ('downright', 1): 96,\n",
              " ('embarrass', 1): 331,\n",
              " ('sinc', 1): 1093,\n",
              " ('thin', 1): 160,\n",
              " ('pure', 1): 284,\n",
              " ('irrelev', 1): 49,\n",
              " ('pad', 1): 95,\n",
              " ('includ', 1): 773,\n",
              " ('sub', 1): 226,\n",
              " ('regard', 1): 183,\n",
              " ('incompet', 1): 84,\n",
              " ('floridian', 1): 4,\n",
              " ('polic', 1): 403,\n",
              " ('forc', 1): 665,\n",
              " ('fbi', 1): 59,\n",
              " ('inspector', 1): 45,\n",
              " ('seem', 1): 3253,\n",
              " ('person', 1): 1292,\n",
              " ('score', 1): 365,\n",
              " ('settl', 1): 67,\n",
              " ('inexplic', 1): 77,\n",
              " ('happen', 1): 1582,\n",
              " ('screen', 1): 1119,\n",
              " ('hate', 1): 579,\n",
              " ('even', 1): 6413,\n",
              " ('gratuit', 1): 101,\n",
              " ('enjoy', 1): 1181,\n",
              " ('better', 1): 2724,\n",
              " ('get', 1): 6134,\n",
              " ('qualiti', 1): 604,\n",
              " ('dialog', 1): 522,\n",
              " ('suffer', 1): 319,\n",
              " ('crap', 1): 680,\n",
              " ('make', 1): 6548,\n",
              " ('realiz', 1): 478,\n",
              " ('delight', 1): 67,\n",
              " ('spirit', 1): 250,\n",
              " ('gone', 1): 331,\n",
              " ('good', 1): 6045,\n",
              " ('sorri', 1): 527,\n",
              " ('everyon', 1): 827,\n",
              " ('suppos', 1): 1099,\n",
              " ('art', 1): 513,\n",
              " ('wow', 1): 188,\n",
              " ('hand', 1): 905,\n",
              " ('gun', 1): 404,\n",
              " ('peopl', 1): 3762,\n",
              " ('blow', 1): 211,\n",
              " ('brain', 1): 317,\n",
              " ('watch', 1): 5970,\n",
              " ('although', 1): 804,\n",
              " ('scene', 1): 4714,\n",
              " ('design', 1): 310,\n",
              " ('photograph', 1): 149,\n",
              " ('direct', 1): 1618,\n",
              " ('excel', 1): 322,\n",
              " ('stori', 1): 4330,\n",
              " ('pain', 1): 568,\n",
              " ('absenc', 1): 44,\n",
              " ('sound', 1): 1112,\n",
              " ('brutal', 1): 148,\n",
              " ('loooonnnnng', 1): 1,\n",
              " ('shot', 1): 1329,\n",
              " ('long', 1): 1402,\n",
              " ('two', 1): 2624,\n",
              " ('sit', 1): 640,\n",
              " ('talk', 1): 936,\n",
              " ('especi', 1): 768,\n",
              " ('dialogu', 1): 867,\n",
              " ('complain', 1): 80,\n",
              " ('hard', 1): 1172,\n",
              " ('time', 1): 6186,\n",
              " ('perform', 1): 1481,\n",
              " ('much', 1): 3980,\n",
              " ('dark', 1): 627,\n",
              " ('sombr', 1): 5,\n",
              " ('uninspir', 1): 129,\n",
              " ('stuff', 1): 536,\n",
              " ('maureen', 1): 11,\n",
              " ('stapleton', 1): 7,\n",
              " ('red', 1): 299,\n",
              " ('dress', 1): 259,\n",
              " ('danc', 1): 395,\n",
              " ('otherwis', 1): 345,\n",
              " ('ripoff', 1): 46,\n",
              " ('bergman', 1): 55,\n",
              " ('fan', 1): 1242,\n",
              " ('f', 1): 234,\n",
              " ('either', 1): 964,\n",
              " ('say', 1): 3319,\n",
              " ('hour', 1): 1088,\n",
              " ('lie', 1): 240,\n",
              " ('sheer', 1): 113,\n",
              " ('brillianc', 1): 22,\n",
              " ('br', 1): 41445,\n",
              " ('turn', 1): 1585,\n",
              " ('thriller', 1): 394,\n",
              " ('suspens', 1): 406,\n",
              " ('comedi', 1): 1441,\n",
              " ('never', 1): 2801,\n",
              " ('laugh', 1): 1392,\n",
              " ('movi', 1): 23466,\n",
              " ('insan', 1): 143,\n",
              " ('develop', 1): 651,\n",
              " ('written', 1): 565,\n",
              " ('depth', 1): 219,\n",
              " ('mess', 1): 521,\n",
              " ('useless', 1): 96,\n",
              " ('wast', 1): 1531,\n",
              " ('bad', 1): 6021,\n",
              " ('lousi', 1): 136,\n",
              " ('overal', 1): 549,\n",
              " ('sure', 1): 1264,\n",
              " ('keep', 1): 864,\n",
              " ('focus', 1): 140,\n",
              " ('classic', 1): 568,\n",
              " ('food', 1): 153,\n",
              " ('processor', 1): 4,\n",
              " ('total', 1): 992,\n",
              " ('inept', 1): 121,\n",
              " ('investig', 1): 194,\n",
              " ('remark', 1): 114,\n",
              " ('low', 1): 1079,\n",
              " ('write', 1): 1015,\n",
              " ('entir', 1): 883,\n",
              " ('durat', 1): 27,\n",
              " ('dare', 1): 107,\n",
              " ('brave', 1): 55,\n",
              " ('creepiest', 1): 2,\n",
              " ('twist', 1): 462,\n",
              " ('ever', 1): 2585,\n",
              " ('clap', 1): 13,\n",
              " ('eye', 1): 775,\n",
              " ('someth', 1): 2348,\n",
              " ('mexican', 1): 79,\n",
              " ('odd', 1): 261,\n",
              " ('religion', 1): 88,\n",
              " ('mix', 1): 248,\n",
              " ('ancient', 1): 104,\n",
              " ('aztec', 1): 16,\n",
              " ('belief', 1): 114,\n",
              " ('tradit', 1): 119,\n",
              " ('christian', 1): 330,\n",
              " ('theolog', 1): 15,\n",
              " ('day', 1): 1415,\n",
              " ('dead', 1): 908,\n",
              " ('half', 1): 1160,\n",
              " ('scari', 1): 470,\n",
              " ('santa', 1): 125,\n",
              " ('clau', 1): 37,\n",
              " ('jolli', 1): 15,\n",
              " ('fat', 1): 172,\n",
              " ('suit', 1): 254,\n",
              " ('alcohol', 1): 74,\n",
              " ('look', 1): 4770,\n",
              " ('rosi', 1): 22,\n",
              " ('cheek', 1): 51,\n",
              " ('sometim', 1): 363,\n",
              " ('rather', 1): 1110,\n",
              " ('skinni', 1): 32,\n",
              " ('sociopath', 1): 19,\n",
              " ('pedophil', 1): 12,\n",
              " ('live', 1): 1356,\n",
              " ('heaven', 1): 141,\n",
              " ('whichev', 1): 11,\n",
              " ('bunch', 1): 473,\n",
              " ('kid', 1): 1295,\n",
              " ('work', 1): 2564,\n",
              " ('harder', 1): 53,\n",
              " ('kathi', 1): 28,\n",
              " ('lee', 1): 330,\n",
              " ('gifford', 1): 2,\n",
              " ('sweat', 1): 31,\n",
              " ('shop', 1): 152,\n",
              " ('sing', 1): 312,\n",
              " ('oh', 1): 819,\n",
              " ('cute', 1): 223,\n",
              " ('song', 1): 594,\n",
              " ('homeland', 1): 6,\n",
              " ('wear', 1): 316,\n",
              " ('cloth', 1): 207,\n",
              " ('stereotyp', 1): 346,\n",
              " ('surpris', 1): 588,\n",
              " ('littl', 1): 2409,\n",
              " ('african', 1): 105,\n",
              " ('american', 1): 1003,\n",
              " ('boy', 1): 760,\n",
              " ('black', 1): 926,\n",
              " ('mammi', 1): 3,\n",
              " ('peep', 1): 18,\n",
              " ('tom', 1): 190,\n",
              " ('pervert', 1): 47,\n",
              " ('listen', 1): 209,\n",
              " ('everyth', 1): 972,\n",
              " ('everybodi', 1): 173,\n",
              " ('sky', 1): 90,\n",
              " ('tell', 1): 1192,\n",
              " ('naughti', 1): 47,\n",
              " ('nice', 1): 787,\n",
              " ('emphasi', 1): 41,\n",
              " ('bet', 1): 140,\n",
              " ('mr', 1): 511,\n",
              " ('elv', 1): 8,\n",
              " ('got', 1): 1583,\n",
              " ('child', 1): 487,\n",
              " ('labor', 1): 35,\n",
              " ('reindeer', 1): 5,\n",
              " ('mechan', 1): 59,\n",
              " ('wind', 1): 193,\n",
              " ('toy', 1): 61,\n",
              " ('float', 1): 56,\n",
              " ('freak', 1): 118,\n",
              " ('show', 1): 3464,\n",
              " ('hover', 1): 8,\n",
              " ('cloud', 1): 39,\n",
              " ('presum', 1): 102,\n",
              " ('held', 1): 142,\n",
              " ('silver', 1): 70,\n",
              " ('line', 1): 1521,\n",
              " ('nemesi', 1): 26,\n",
              " ('devil', 1): 168,\n",
              " ('lord', 1): 125,\n",
              " ('savior', 1): 11,\n",
              " ('weird', 1): 284,\n",
              " ('anyhoo', 1): 4,\n",
              " ('satan', 1): 93,\n",
              " ('send', 1): 186,\n",
              " ('minion', 1): 33,\n",
              " ('minc', 1): 3,\n",
              " ('pranc', 1): 9,\n",
              " ('name', 1): 1259,\n",
              " ('pitch', 1): 74,\n",
              " ('tri', 1): 3109,\n",
              " ('screw', 1): 102,\n",
              " ('christma', 1): 188,\n",
              " ('let', 1): 1345,\n",
              " ('straight', 1): 399,\n",
              " ('purest', 1): 2,\n",
              " ('evil', 1): 700,\n",
              " ('ruin', 1): 300,\n",
              " ('commerci', 1): 148,\n",
              " ('greed', 1): 24,\n",
              " ('driven', 1): 70,\n",
              " ('kind', 1): 1364,\n",
              " ('redund', 1): 40,\n",
              " ('ineffectu', 1): 16,\n",
              " ('children', 1): 571,\n",
              " ('luck', 1): 109,\n",
              " ('strongli', 1): 50,\n",
              " ('struck', 1): 46,\n",
              " ('storylin', 1): 355,\n",
              " ('saintli', 1): 16,\n",
              " ('lupe', 1): 6,\n",
              " ('famili', 1): 887,\n",
              " ('poor', 1): 1178,\n",
              " ('doll', 1): 93,\n",
              " ('parent', 1): 326,\n",
              " ('afford', 1): 67,\n",
              " ('buy', 1): 422,\n",
              " ('spent', 1): 321,\n",
              " ('money', 1): 1264,\n",
              " ('cardboard', 1): 73,\n",
              " ('built', 1): 69,\n",
              " ('encourag', 1): 54,\n",
              " ('realiti', 1): 287,\n",
              " ('way', 1): 3405,\n",
              " ('pray', 1): 53,\n",
              " ('god', 1): 695,\n",
              " ('holi', 1): 77,\n",
              " ('resist', 1): 61,\n",
              " ('temptat', 1): 10,\n",
              " ('thee', 1): 7,\n",
              " ('reward', 1): 41,\n",
              " ('given', 1): 752,\n",
              " ('creepi', 1): 222,\n",
              " ('chucki', 1): 23,\n",
              " ('sister', 1): 268,\n",
              " ('along', 1): 717,\n",
              " ('manag', 1): 560,\n",
              " ('stuck', 1): 165,\n",
              " ('tree', 1): 144,\n",
              " ('uh', 1): 43,\n",
              " ('huh', 1): 79,\n",
              " ('whenc', 1): 2,\n",
              " ('rescu', 1): 136,\n",
              " ('merlin', 1): 9,\n",
              " ('mythic', 1): 19,\n",
              " ('druidic', 1): 2,\n",
              " ('appear', 1): 1127,\n",
              " ('tale', 1): 247,\n",
              " ('anyth', 1): 1488,\n",
              " ('disapprov', 1): 11,\n",
              " ('magic', 1): 180,\n",
              " ('burn', 1): 211,\n",
              " ('stake', 1): 25,\n",
              " ('hundr', 1): 166,\n",
              " ('ago', 1): 411,\n",
              " ('ask', 1): 706,\n",
              " ('come', 1): 2583,\n",
              " ('aspect', 1): 282,\n",
              " ('assum', 1): 217,\n",
              " ('must', 1): 1232,\n",
              " ('finish', 1): 360,\n",
              " ('wonder', 1): 992,\n",
              " ('eggnog', 1): 4,\n",
              " ('drank', 1): 3,\n",
              " ('spike', 1): 49,\n",
              " ('probabl', 1): 1224,\n",
              " ('giant', 1): 222,\n",
              " ('dt', 1): 2,\n",
              " ('might', 1): 1296,\n",
              " ('flick', 1): 828,\n",
              " ('howev', 1): 1383,\n",
              " ('mani', 1): 2329,\n",
              " ('poorli', 1): 550,\n",
              " ('done', 1): 1196,\n",
              " ('due', 1): 374,\n",
              " ('languag', 1): 193,\n",
              " ('transfer', 1): 76,\n",
              " ('read', 1): 1258,\n",
              " ('becom', 1): 1053,\n",
              " ('els', 1): 986,\n",
              " ('rate', 1): 958,\n",
              " ('concern', 1): 206,\n",
              " ('wait', 1): 588,\n",
              " ('rent', 1): 716,\n",
              " ('real', 1): 1641,\n",
              " ('boardman', 1): 6,\n",
              " ('ohio', 1): 10,\n",
              " ('find', 1): 1935,\n",
              " ('english', 1): 342,\n",
              " ('version', 1): 800,\n",
              " ('compar', 1): 392,\n",
              " ('avail', 1): 132,\n",
              " ('guess', 1): 762,\n",
              " ('actual', 1): 2380,\n",
              " ('japan', 1): 92,\n",
              " ('man', 1): 2043,\n",
              " ('slash', 1): 45,\n",
              " ('wife', 1): 683,\n",
              " ('death', 1): 816,\n",
              " ('commit', 1): 201,\n",
              " ('suicid', 1): 162,\n",
              " ('gori', 1): 132,\n",
              " ('bloodi', 1): 156,\n",
              " ('sequenc', 1): 654,\n",
              " ('jump', 1): 250,\n",
              " ('present', 1): 492,\n",
              " ('precis', 1): 33,\n",
              " ('ted', 1): 52,\n",
              " ('edward', 1): 66,\n",
              " ('albert', 1): 38,\n",
              " ('laura', 1): 57,\n",
              " ('susan', 1): 66,\n",
              " ('georg', 1): 289,\n",
              " ('annoy', 1): 715,\n",
              " ('hubbi', 1): 18,\n",
              " ('took', 1): 445,\n",
              " ('three', 1): 901,\n",
              " ('around', 1): 1505,\n",
              " ('ghost', 1): 291,\n",
              " ('makeup', 1): 126,\n",
              " ('hyster', 1): 70,\n",
              " ('life', 1): 1824,\n",
              " ('hell', 1): 567,\n",
              " ('ok', 1): 658,\n",
              " ('hopeless', 1): 33,\n",
              " ('open', 1): 871,\n",
              " ('end', 1): 3811,\n",
              " ('noth', 1): 2388,\n",
              " ('attack', 1): 427,\n",
              " ('crab', 1): 24,\n",
              " ('uproari', 1): 3,\n",
              " ('fake', 1): 338,\n",
              " ('swear', 1): 89,\n",
              " ('saw', 1): 1133,\n",
              " ('string', 1): 113,\n",
              " ('pull', 1): 365,\n",
              " ('mutter', 1): 18,\n",
              " ('sex', 1): 849,\n",
              " ('first', 1): 3330,\n",
              " ('minut', 1): 2129,\n",
              " ('bodi', 1): 621,\n",
              " ('anoth', 1): 1700,\n",
              " ('later', 1): 754,\n",
              " ('necessari', 1): 102,\n",
              " ('silli', 1): 539,\n",
              " ('exorc', 1): 19,\n",
              " ('toward', 1): 359,\n",
              " ('fight', 1): 862,\n",
              " ('doug', 1): 44,\n",
              " ('mcclure', 1): 5,\n",
              " ('seen', 1): 2669,\n",
              " ('believ', 1): 1609,\n",
              " ('act', 1): 4248,\n",
              " ('husband', 1): 377,\n",
              " ('pretti', 1): 1657,\n",
              " ('friend', 1): 1223,\n",
              " ('alway', 1): 923,\n",
              " ('terrif', 1): 50,\n",
              " ('give', 1): 2225,\n",
              " ('lift', 1): 99,\n",
              " ('save', 1): 942,\n",
              " ('close', 1): 707,\n",
              " ('asid', 1): 194,\n",
              " ('piec', 1): 916,\n",
              " ('bomb', 1): 235,\n",
              " ('bottom', 1): 247,\n",
              " ('barrel', 1): 71,\n",
              " ('worst', 1): 1872,\n",
              " ('norri', 1): 80,\n",
              " ('dull', 1): 563,\n",
              " ('portray', 1): 634,\n",
              " ('anonym', 1): 25,\n",
              " ('great', 1): 2206,\n",
              " ('trait', 1): 34,\n",
              " ('action', 1): 1373,\n",
              " ('protagonist', 1): 178,\n",
              " ('christoph', 1): 128,\n",
              " ('neam', 1): 5,\n",
              " ('overact', 1): 97,\n",
              " ('deliv', 1): 366,\n",
              " ('level', 1): 478,\n",
              " ('tame', 1): 66,\n",
              " ('paper', 1): 165,\n",
              " ('horrif', 1): 85,\n",
              " ('clich', 1): 644,\n",
              " ('fifti', 1): 62,\n",
              " ('fill', 1): 374,\n",
              " ('room', 1): 425,\n",
              " ('smoke', 1): 140,\n",
              " ('men', 1): 711,\n",
              " ('rubber', 1): 79,\n",
              " ('expect', 1): 1292,\n",
              " ('audienc', 1): 1111,\n",
              " ('terror', 1): 123,\n",
              " ('visual', 1): 340,\n",
              " ('unfortun', 1): 837,\n",
              " ('cheap', 1): 583,\n",
              " ('porn', 1): 184,\n",
              " ('miami', 1): 21,\n",
              " ('vice', 1): 45,\n",
              " ('rip', 1): 361,\n",
              " ('sprinkl', 1): 22,\n",
              " ('spawn', 1): 37,\n",
              " ('yawn', 1): 82,\n",
              " ('notic', 1): 361,\n",
              " ('cours', 1): 899,\n",
              " ('unnecessari', 1): 124,\n",
              " ('amount', 1): 226,\n",
              " ('nuditi', 1): 302,\n",
              " ('ooz', 1): 19,\n",
              " ('lot', 1): 1821,\n",
              " ('annik', 1): 5,\n",
              " ('borel', 1): 5,\n",
              " ('play', 1): 2916,\n",
              " ('disturb', 1): 230,\n",
              " ('woman', 1): 1085,\n",
              " ('ancestor', 1): 25,\n",
              " ('eerili', 1): 15,\n",
              " ('resembl', 1): 172,\n",
              " ('werewolf', 1): 105,\n",
              " ('fate', 1): 103,\n",
              " ('destin', 1): 40,\n",
              " ('found', 1): 988,\n",
              " ('quit', 1): 1346,\n",
              " ('interest', 1): 1965,\n",
              " ('origin', 1): 1744,\n",
              " ('wolf', 1): 63,\n",
              " ('intend', 1): 191,\n",
              " ('psycholog', 1): 105,\n",
              " ('univers', 1): 197,\n",
              " ('threw', 1): 71,\n",
              " ('see', 1): 5184,\n",
              " ('n', 1): 114,\n",
              " ('extra', 1): 188,\n",
              " ('buck', 1): 143,\n",
              " ('concept', 1): 290,\n",
              " ('someon', 1): 1263,\n",
              " ('search', 1): 180,\n",
              " ('instead', 1): 1150,\n",
              " ('she', 1): 12,\n",
              " ('begin', 1): 1150,\n",
              " ('thrill', 1): 159,\n",
              " ('scenario', 1): 116,\n",
              " ('fail', 1): 862,\n",
              " ('ad', 1): 362,\n",
              " ('part', 1): 2080,\n",
              " ('refer', 1): 305,\n",
              " ('excit', 1): 358,\n",
              " ('upon', 1): 374,\n",
              " ('descript', 1): 86,\n",
              " ('slowli', 1): 133,\n",
              " ('cover', 1): 454,\n",
              " ('expos', 1): 98,\n",
              " ('main', 1): 1012,\n",
              " ('breast', 1): 107,\n",
              " ('often', 1): 515,\n",
              " ('possibl', 1): 870,\n",
              " ('decent', 1): 715,\n",
              " ('actor', 1): 2873,\n",
              " ('psychot', 1): 39,\n",
              " ('role', 1): 1351,\n",
              " ('danniel', 1): 1,\n",
              " ('nut', 1): 70,\n",
              " ('run', 1): 1294,\n",
              " ('snarl', 1): 14,\n",
              " ('snap', 1): 33,\n",
              " ('skill', 1): 178,\n",
              " ('moment', 1): 986,\n",
              " ('camera', 1): 975,\n",
              " ('light', 1): 624,\n",
              " ('hideous', 1): 26,\n",
              " ('execut', 1): 323,\n",
              " ('throughout', 1): 534,\n",
              " ('privat', 1): 127,\n",
              " ('collector', 1): 14,\n",
              " ('curiou', 1): 78,\n",
              " ('imdb', 1): 355,\n",
              " ('vote', 1): 171,\n",
              " ('extern', 1): 14,\n",
              " ('comment', 1): 652,\n",
              " ('pleasant', 1): 63,\n",
              " ('usual', 1): 717,\n",
              " ('uninterest', 1): 144,\n",
              " ('giallo', 1): 35,\n",
              " ('ye', 1): 666,\n",
              " ('cinematographi', 1): 288,\n",
              " ('ordinari', 1): 112,\n",
              " ('occur', 1): 159,\n",
              " ('normal', 1): 295,\n",
              " ('tit', 1): 28,\n",
              " ('bizarr', 1): 228,\n",
              " ('surreal', 1): 47,\n",
              " ('nonsens', 1): 187,\n",
              " ('atmospher', 1): 234,\n",
              " ('appreci', 1): 208,\n",
              " ('edit', 1): 628,\n",
              " ('final', 1): 1178,\n",
              " ('entertain', 1): 994,\n",
              " ('tnt', 1): 10,\n",
              " ('corni', 1): 124,\n",
              " ('cheezi', 1): 13,\n",
              " ('certain', 1): 270,\n",
              " ('point', 1): 1803,\n",
              " ('began', 1): 116,\n",
              " ('sock', 1): 27,\n",
              " ('truth', 1): 265,\n",
              " ('classifi', 1): 31,\n",
              " ('adventur', 1): 182,\n",
              " ('hilari', 1): 363,\n",
              " ('delon', 1): 10,\n",
              " ('kennedi', 1): 75,\n",
              " ('loop', 1): 28,\n",
              " ('avoid', 1): 593,\n",
              " ('french', 1): 300,\n",
              " ('missil', 1): 49,\n",
              " ('wagner', 1): 44,\n",
              " ('destroy', 1): 311,\n",
              " ('concord', 1): 52,\n",
              " ('fearless', 1): 11,\n",
              " ('leader', 1): 128,\n",
              " ('decid', 1): 822,\n",
              " ('shoot', 1): 545,\n",
              " ('flare', 1): 13,\n",
              " ('window', 1): 159,\n",
              " ('stop', 1): 730,\n",
              " ('heat', 1): 55,\n",
              " ('seek', 1): 101,\n",
              " ('yet', 1): 909,\n",
              " ('funni', 1): 1852,\n",
              " ('kicker', 1): 8,\n",
              " ('though', 1): 1721,\n",
              " ('malfunct', 1): 5,\n",
              " ('fix', 1): 71,\n",
              " ('cockpit', 1): 16,\n",
              " ('hold', 1): 379,\n",
              " ('lack', 1): 991,\n",
              " ('yeah', 1): 254,\n",
              " ('land', 1): 291,\n",
              " ('pari', 1): 109,\n",
              " ('prostitut', 1): 76,\n",
              " ('flight', 1): 91,\n",
              " ('attend', 1): 81,\n",
              " ('switch', 1): 96,\n",
              " ('saboteur', 1): 18,\n",
              " ('ten', 1): 372,\n",
              " ('rest', 1): 821,\n",
              " ('plane', 1): 208,\n",
              " ('passeng', 1): 51,\n",
              " ('right', 1): 1443,\n",
              " ('front', 1): 266,\n",
              " ('star', 1): 1677,\n",
              " ('okay', 1): 411,\n",
              " ('agre', 1): 302,\n",
              " ('barney', 1): 72,\n",
              " ('hater', 1): 13,\n",
              " ('site', 1): 121,\n",
              " ('ugli', 1): 236,\n",
              " ('obnoxi', 1): 113,\n",
              " ('lop', 1): 6,\n",
              " ('side', 1): 541,\n",
              " ('unrealist', 1): 183,\n",
              " ('tick', 1): 27,\n",
              " ('gay', 1): 352,\n",
              " ('lesbian', 1): 158,\n",
              " ('bisexu', 1): 19,\n",
              " ('rel', 1): 148,\n",
              " ('problem', 1): 1099,\n",
              " ('creator', 1): 97,\n",
              " ('use', 1): 2080,\n",
              " ('derogatori', 1): 2,\n",
              " ('homosexu', 1): 67,\n",
              " ('mean', 1): 1340,\n",
              " ('mascara', 1): 10,\n",
              " ('color', 1): 233,\n",
              " ('purpl', 1): 17,\n",
              " ('pink', 1): 46,\n",
              " ('manli', 1): 17,\n",
              " ('bosom', 1): 11,\n",
              " ('sag', 1): 6,\n",
              " ('abdomen', 1): 6,\n",
              " ('femal', 1): 521,\n",
              " ('south', 1): 194,\n",
              " ('park', 1): 212,\n",
              " ('distinguish', 1): 50,\n",
              " ('fantasi', 1): 171,\n",
              " ('handicap', 1): 34,\n",
              " ('girlfriend', 1): 256,\n",
              " ('pinkish', 1): 3,\n",
              " ('sequin', 1): 3,\n",
              " ('true', 1): 652,\n",
              " ('claim', 1): 249,\n",
              " ('individu', 1): 133,\n",
              " ('mockeri', 1): 35,\n",
              " ('went', 1): 683,\n",
              " ('ate', 1): 22,\n",
              " ('fri', 1): 42,\n",
              " ('chicken', 1): 51,\n",
              " ('watermelon', 1): 4,\n",
              " ('air', 1): 317,\n",
              " ('neg', 1): 150,\n",
              " ('five', 1): 446,\n",
              " ('less', 1): 775,\n",
              " ('insult', 1): 283,\n",
              " ('sidney', 1): 25,\n",
              " ('j', 1): 137,\n",
              " ('furi', 1): 40,\n",
              " ('dolph', 1): 52,\n",
              " ('lundgren', 1): 66,\n",
              " ('liner', 1): 91,\n",
              " ('user', 1): 79,\n",
              " ('nd', 1): 49,\n",
              " ('depreci', 1): 5,\n",
              " ('bother', 1): 412,\n",
              " ('hey', 1): 209,\n",
              " ('accept', 1): 289,\n",
              " ('product', 1): 1002,\n",
              " ('understand', 1): 868,\n",
              " ('clearli', 1): 377,\n",
              " ('public', 1): 232,\n",
              " ('stunt', 1): 130,\n",
              " ('detent', 1): 15,\n",
              " ('regular', 1): 89,\n",
              " ('nu', 1): 13,\n",
              " ('imag', 1): 325,\n",
              " ('garbag', 1): 328,\n",
              " ('convinc', 1): 418,\n",
              " ('ex', 1): 195,\n",
              " ('militari', 1): 162,\n",
              " ('histori', 1): 435,\n",
              " ('teacher', 1): 268,\n",
              " ('assign', 1): 62,\n",
              " ('rough', 1): 65,\n",
              " ('school', 1): 726,\n",
              " ('emotionless', 1): 22,\n",
              " ('contriv', 1): 180,\n",
              " ('inabl', 1): 42,\n",
              " ('visibl', 1): 37,\n",
              " ('juvenil', 1): 57,\n",
              " ('delinqu', 1): 21,\n",
              " ('natur', 1): 469,\n",
              " ('element', 1): 409,\n",
              " ('potenti', 1): 354,\n",
              " ('budget', 1): 1129,\n",
              " ('weekend', 1): 87,\n",
              " ('high', 1): 836,\n",
              " ('secur', 1): 94,\n",
              " ('teen', 1): 259,\n",
              " ('war', 1): 650,\n",
              " ('veteran', 1): 66,\n",
              " ('group', 1): 515,\n",
              " ('ruthless', 1): 26,\n",
              " ('crimin', 1): 184,\n",
              " ('breakfast', 1): 38,\n",
              " ('club', 1): 183,\n",
              " ('meet', 1): 519,\n",
              " ('die', 1): 891,\n",
              " ('panic', 1): 29,\n",
              " ('full', 1): 631,\n",
              " ('unbeliev', 1): 300,\n",
              " ('situat', 1): 427,\n",
              " ('forget', 1): 310,\n",
              " ('alex', 1): 91,\n",
              " ('karzi', 1): 3,\n",
              " ('kata', 1): 4,\n",
              " ('dob', 1): 4,\n",
              " ('bonni', 1): 20,\n",
              " ('clyde', 1): 21,\n",
              " ('coupl', 1): 824,\n",
              " ('sam', 1): 158,\n",
              " ('rockwel', 1): 6,\n",
              " ('milla', 1): 11,\n",
              " ('jovovich', 1): 5,\n",
              " ('crazi', 1): 245,\n",
              " ('style', 1): 616,\n",
              " ('suppli', 1): 78,\n",
              " ('enough', 1): 1580,\n",
              " ('fresh', 1): 113,\n",
              " ('prevent', 1): 93,\n",
              " ('drop', 1): 223,\n",
              " ('ground', 1): 208,\n",
              " ('zero', 1): 212,\n",
              " ('shame', 1): 331,\n",
              " ('talent', 1): 704,\n",
              " ('involv', 1): 809,\n",
              " ('self', 1): 473,\n",
              " ('consciou', 1): 32,\n",
              " ('almost', 1): 1239,\n",
              " ('caricatur', 1): 57,\n",
              " ('disappoint', 1): 990,\n",
              " ('gerard', 1): 19,\n",
              " ('depardieu', 1): 13,\n",
              " ('best', 1): 1721,\n",
              " ('bianca', 1): 2,\n",
              " ('gervai', 1): 1,\n",
              " ('posit', 1): 394,\n",
              " ('note', 1): 359,\n",
              " ('newcom', 1): 20,\n",
              " ('juliett', 1): 11,\n",
              " ('gosselin', 1): 1,\n",
              " ('amaz', 1): 325,\n",
              " ('rememb', 1): 650,\n",
              " ('apolog', 1): 47,\n",
              " ('analysi', 1): 23,\n",
              " ('aw', 1): 1322,\n",
              " ('bug', 1): 89,\n",
              " ('director', 1): 2215,\n",
              " ('particular', 1): 257,\n",
              " ('toss', 1): 61,\n",
              " ('hat', 1): 98,\n",
              " ('join', 1): 125,\n",
              " ('naysay', 1): 3,\n",
              " ('wicker', 1): 13,\n",
              " ('cornucopia', 1): 3,\n",
              " ('music', 1): 1271,\n",
              " ('sensual', 1): 14,\n",
              " ('pagan', 1): 19,\n",
              " ('modern', 1): 236,\n",
              " ('world', 1): 1089,\n",
              " ('clash', 1): 13,\n",
              " ('said', 1): 1023,\n",
              " ('crowd', 1): 107,\n",
              " ('remak', 1): 326,\n",
              " ('exampl', 1): 689,\n",
              " ('invas', 1): 39,\n",
              " ('snatcher', 1): 12,\n",
              " ('stand', 1): 550,\n",
              " ('campi', 1): 105,\n",
              " ('today', 1): 278,\n",
              " ('standard', 1): 360,\n",
              " ('proud', 1): 50,\n",
              " ('kurt', 1): 11,\n",
              " ('russel', 1): 65,\n",
              " ('favorit', 1): 270,\n",
              " ('small', 1): 617,\n",
              " ('minor', 1): 169,\n",
              " ('accus', 1): 69,\n",
              " ('diss', 1): 5,\n",
              " ('solidifi', 1): 3,\n",
              " ('neil', 1): 29,\n",
              " ('labut', 1): 9,\n",
              " ('sexism', 1): 11,\n",
              " ('misogynist', 1): 10,\n",
              " ('tendenc', 1): 28,\n",
              " ('seriou', 1): 408,\n",
              " ('green', 1): 159,\n",
              " ('anti', 1): 182,\n",
              " ('cage', 1): 110,\n",
              " ('hit', 1): 564,\n",
              " ('women', 1): 775,\n",
              " ('frustrat', 1): 130,\n",
              " ('thwart', 1): 4,\n",
              " ('miss', 1): 911,\n",
              " ('react', 1): 74,\n",
              " ('island', 1): 383,\n",
              " ('suspect', 1): 215,\n",
              " ('forthcom', 1): 6,\n",
              " ('creat', 1): 531,\n",
              " ('societi', 1): 212,\n",
              " ('particip', 1): 50,\n",
              " ('goddess', 1): 29,\n",
              " ('base', 1): 569,\n",
              " ('threat', 1): 52,\n",
              " ('came', 1): 653,\n",
              " ('male', 1): 347,\n",
              " ('sexual', 1): 353,\n",
              " ('hierarchi', 1): 2,\n",
              " ('metaphor', 1): 40,\n",
              " ('bee', 1): 16,\n",
              " ('drone', 1): 37,\n",
              " ('etc', 1): 548,\n",
              " ('bit', 1): 1195,\n",
              " ('heavi', 1): 212,\n",
              " ('conveni', 1): 68,\n",
              " ('allergi', 1): 2,\n",
              " ('kept', 1): 343,\n",
              " ('back', 1): 1951,\n",
              " ('mere', 1): 210,\n",
              " ('physic', 1): 195,\n",
              " ('treat', 1): 237,\n",
              " ('grunt', 1): 25,\n",
              " ('special', 1): 993,\n",
              " ('supernatur', 1): 96,\n",
              " ('power', 1): 598,\n",
              " ('pregnant', 1): 87,\n",
              " ('old', 1): 1704,\n",
              " ('blond', 1): 167,\n",
              " ('waif', 1): 6,\n",
              " ('escap', 1): 329,\n",
              " ('domin', 1): 66,\n",
              " ('weapon', 1): 154,\n",
              " ('beyond', 1): 457,\n",
              " ('cut', 1): 722,\n",
              " ('tool', 1): 69,\n",
              " ('unhappi', 1): 31,\n",
              " ('content', 1): 153,\n",
              " ('unabl', 1): 98,\n",
              " ('speak', 1): 480,\n",
              " ('defend', 1): 61,\n",
              " ('commun', 1): 191,\n",
              " ('ran', 1): 99,\n",
              " ('castrat', 1): 8,\n",
              " ('stepford', 1): 4,\n",
              " ('wive', 1): 46,\n",
              " ('symptom', 1): 12,\n",
              " ('afraid', 1): 139,\n",
              " ('may', 1): 1138,\n",
              " ('sh', 1): 62,\n",
              " ('togeth', 1): 799,\n",
              " ('truli', 1): 625,\n",
              " ('citizen', 1): 75,\n",
              " ('view', 1): 725,\n",
              " ('unintent', 1): 153,\n",
              " ('humor', 1): 530,\n",
              " ('knock', 1): 118,\n",
              " ('left', 1): 958,\n",
              " ('egalitarian', 1): 1,\n",
              " ('uninhibit', 1): 4,\n",
              " ('lascivi', 1): 9,\n",
              " ('push', 1): 146,\n",
              " ('button', 1): 73,\n",
              " ('discomfort', 1): 8,\n",
              " ('exploit', 1): 244,\n",
              " ('cop', 1): 464,\n",
              " ('lewd', 1): 10,\n",
              " ('adult', 1): 282,\n",
              " ('logic', 1): 187,\n",
              " ('mental', 1): 188,\n",
              " ('leap', 1): 38,\n",
              " ('abus', 1): 151,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "## Run this cell to get an idea about the corpus of words and their occurrence along with labels.\n",
        "## In this, we are computing the frequency of occurrence of word given that a review is 'positive'.\n",
        "## Similarly, we also compute the frequence of occurence of word given that a review is 'negative'.\n",
        "freqs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759c24bc",
      "metadata": {
        "id": "759c24bc"
      },
      "source": [
        "## Q4. Training the Naive Bayes Model: (20 points)\n",
        "\n",
        "Now we are in the training phase of the Naive Bayes algorithm. In this cell, take a look at the ways to calculate the log likelihood and log prior values as these are important for testing in the next few cells.\n",
        "\n",
        "Also calculate the frequency of occurrence of words where the output is negative. In the same way, calculate the word frequency count using the above functions in order to compute the log likelihood.\n",
        "\n",
        "Return the logprior and loglikelihood output by the model from this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "a7f280e3",
      "metadata": {
        "id": "a7f280e3"
      },
      "outputs": [],
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary from (word, label) to how often the word appears\n",
        "        train_x: a list of reviews\n",
        "        train_y: a list of labels correponding to the reviews (0,1)\n",
        "    Output:\n",
        "        logprior: the log prior. (equation 3 above)\n",
        "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
        "    '''\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "\n",
        "    # calculate V, the number of unique words in the vocabulary\n",
        "    vocab = set(word for review in train_x for word in clean_review(review).split())\n",
        "    V = len(vocab)\n",
        "\n",
        "    # calculate num_pos and num_neg - the total number of positive and negative words for all documents\n",
        "    num_pos = num_neg = 0\n",
        "    for pair in freqs.keys():\n",
        "        # if the label is positive (greater than zero)\n",
        "        if pair[1] > 0:\n",
        "          num_pos += freqs[pair]\n",
        "\n",
        "        # else, the label is negative\n",
        "        else:\n",
        "          # increment the number of negative words by the count for this (word,label) pair\n",
        "          num_neg += freqs[pair]\n",
        "\n",
        "    # Calculate num_doc, the number of documents\n",
        "    num_doc = len(train_x)\n",
        "\n",
        "    # Calculate D_pos, the number of positive documents\n",
        "    pos_num_docs = sum(1 for y in train_y if y == 1)\n",
        "\n",
        "    # Calculate D_neg, the number of negative documents\n",
        "    neg_num_docs = num_doc - pos_num_docs\n",
        "\n",
        "    # Calculate logprior\n",
        "    logprior = math.log(pos_num_docs / num_doc)\n",
        "\n",
        "    # For each word in the vocabulary...\n",
        "    for word in vocab:\n",
        "        # get the positive and negative frequency of the word\n",
        "        freq_pos = freqs.get((word, 1), 0)\n",
        "        freq_neg = freqs.get((word, 0), 0)\n",
        "\n",
        "        # calculate the probability that each word is positive, and negative\n",
        "        p_w_pos = (freq_pos + 1) / (num_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (num_neg + V)\n",
        "\n",
        "        # calculate the log likelihood of the word\n",
        "        loglikelihood[word] = math.log(p_w_pos) - math.log(p_w_neg)\n",
        "\n",
        "\n",
        "    return logprior, loglikelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "1561d892",
      "metadata": {
        "id": "1561d892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f72ef3-c5b0-48ad-afb0-6b26342738f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.6931471805599453\n",
            "43501\n"
          ]
        }
      ],
      "source": [
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b51303",
      "metadata": {
        "id": "78b51303"
      },
      "source": [
        "## Q5. Implementing Naive Bayes Predict Function: (10 points)\n",
        "\n",
        "It is now time to make our prediction as to whether a given review is negative or positive respectively.\n",
        "\n",
        "After adding the log likelihood values, ensure that the output is 1 (negative) if the sum of the log likelihood value is greater than 0 and 0 (positive) if the sum of the log likelihood is less than or equal to 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "b692c2f9",
      "metadata": {
        "id": "b692c2f9"
      },
      "outputs": [],
      "source": [
        "# TASK 4 CELL\n",
        "\n",
        "def naive_bayes_predict(review, logprior, loglikelihood):\n",
        "    '''\n",
        "    Params:\n",
        "        review: a string\n",
        "        logprior: a number\n",
        "        loglikelihood: a dictionary of words mapping to numbers\n",
        "    Return:\n",
        "        total_prob: the sum of all the loglikelihoods of each word in the review (if found in the dictionary) + logprior (a number)\n",
        "\n",
        "    '''\n",
        "\n",
        "      # process the review to get a list of words\n",
        "    word_l = clean_review(review).split()\n",
        "\n",
        "    # initialize probability to zero\n",
        "    total_prob = 0\n",
        "\n",
        "    # add the logprior\n",
        "    total_prob += logprior\n",
        "\n",
        "    for word in word_l:\n",
        "\n",
        "        # check if the word exists in the loglikelihood dictionary\n",
        "        if word in loglikelihood:\n",
        "            # add the log likelihood of that word to the probability\n",
        "            total_prob+= loglikelihood[word]\n",
        "\n",
        "    #print(f\"The total_probability is {total_prob}\")\n",
        "\n",
        "    #After adding the log likelihood values, ensure that the output is 1 (negative) if the sum of the log likelihood value is\n",
        "    #greater than 0 and 0(positive) if the sum of the log likelihood is less than or equal to 0.\n",
        "    if total_prob > 0:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "4b170333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b170333",
        "outputId": "5d43f5cf-6584-4478-b312-6043e09314df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected output is 1\n"
          ]
        }
      ],
      "source": [
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "\n",
        "# Experiment with your own review.\n",
        "my_review = \"I thought this series was going to be another fun, action series with some dynamic plots and great performances. I was wrong. While I like Jamie Denton, this show is hardly worth watching at all, unless you enjoy watching some people brutalized and the actions of the agents supposedly warranted under the theme of national security. The show is great propaganda for the current government, and spews out jingoism as though we talk that way every day. After a couple of episodes, it was boring the hell out of me, and I started watching reruns of House Invaders on BBCAmerica instead. Rather watch CSI and Without a Trace, without a doubt.\"\n",
        "p = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6242708f",
      "metadata": {
        "id": "6242708f"
      },
      "source": [
        "### Expected Output :\n",
        "The expected output is 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c4eeb71",
      "metadata": {
        "id": "7c4eeb71"
      },
      "source": [
        "## Q6. Implementing Naive Bayes Test function: (10 points)\n",
        "\n",
        "In this function, implement the previous functions such as naive_bayes_predict to get the predictions for the test set.\n",
        "\n",
        "In addition to this, the function should return the total number of reviews that it correctly classified as 'positive' or 'negative'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "66a511e7",
      "metadata": {
        "id": "66a511e7"
      },
      "outputs": [],
      "source": [
        "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: A list of reviews\n",
        "        test_y: the corresponding labels for the list of reviews\n",
        "        logprior: the logprior\n",
        "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
        "    Output:\n",
        "        accuracy: (# of reviews classified correctly)/(total # of reviews)\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "\n",
        "\n",
        "    y_hats = []\n",
        "    for review in test_x:\n",
        "      total_prob = naive_bayes_predict(review, logprior, loglikelihood)\n",
        "        # if the prediction is > 0\n",
        "      if total_prob > 0:\n",
        "        # the predicted class is 1\n",
        "        y_hat_i = 1\n",
        "      else:\n",
        "        # otherwise the predicted class is 0\n",
        "        y_hat_i = 0\n",
        "      # append the predicted class to the list y_hats\n",
        "      y_hats.append(y_hat_i)\n",
        "\n",
        "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
        "    error = sum(abs(y_hat - y_true) for y_hat, y_true in zip(y_hats, test_y)) / len(test_y)\n",
        "\n",
        "\n",
        "    accuracy = 1 - error\n",
        "\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "8a9c5d9d",
      "metadata": {
        "id": "8a9c5d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcd641d-5dda-422d-8d7a-d9f06b425039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you like original gut wrenching laughter you will like this movie. If you are young or old then y -> 0.00\n",
            "What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative  -> 1.00\n",
            "I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the -> 0.00\n",
            "Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement val -> 1.00\n"
          ]
        }
      ],
      "source": [
        "# For grading purpose only\n",
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "\n",
        "# Run this cell to test your function\n",
        "\n",
        "for review in [\"If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\",\n",
        "                \"What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative direction, too. Some VERY faint echoes of Fargo here, but it just doesn't come off.\",\n",
        "                \"I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the romance between Joe and Jean keeps me on the edge of my seat, plus I still think Bryan Brown is the tops. Brilliant Film.\",\n",
        "                \"Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement value. About as unentertaining, uninstructive and just plain dull as a film can be.\"]:\n",
        "    p = naive_bayes_predict(review, logprior, loglikelihood)\n",
        "    print(f'{review[:100]} -> {p:.2f}')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e2ef98",
      "metadata": {
        "id": "43e2ef98"
      },
      "source": [
        "### Expected Output :\n",
        "\n",
        "If you like original gut wrenching laughter you will like this movie. If you are young or old then y -> 0.00 <br>\n",
        "What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative  -> 1.00<br>\n",
        "I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the -> 0.00 <br>\n",
        "Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement val -> 1.00\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "216fa97a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "216fa97a",
        "outputId": "e7195fb4-a59f-44fd-c7e5-ab8c76a5d0c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# Feel free to check the sentiment of your own review below\n",
        "my_review = 'The moview was very boring, I wanted to leave in the middle'\n",
        "naive_bayes_predict(my_review, logprior, loglikelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a45e4f0",
      "metadata": {
        "id": "8a45e4f0"
      },
      "source": [
        "### Expected Output :\n",
        "1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mAIkM4aCC1H7",
      "metadata": {
        "id": "mAIkM4aCC1H7"
      },
      "source": [
        "# Q7. Evaluate the accuracy (15 Points)\n",
        "1. Split your data into training and test sets using random selection. Set the seed as parameter of the function so that user can select a different training and test set by changing seed.\n",
        "\n",
        "2. Calculate model paramters with training set.\n",
        "\n",
        "3. Print confusion matrix for training and test set.\n",
        "\n",
        "4. Examine False Positive and False Negative cases and provide reasoning why they get misclassified."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Split your data into training and test sets using random selection.\n",
        "#Set the seed as parameter of the function so that user can select a different training and test set by changing seed.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure the sentiment is encoded correctly (0 for negative, 1 for positive)\n",
        "df_upsampled['sentiment'] = df_upsampled['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Splitting the data into positive and negative sentiment\n",
        "positive_data = df_upsampled[df_upsampled['sentiment'] == 1]\n",
        "negative_data = df_upsampled[df_upsampled['sentiment'] == 0]\n",
        "\n",
        "# Splitting the data into training and testing sets with custom seed\n",
        "def split_data(positive_data, negative_data, seed=None):\n",
        "    # Specify the number of samples for training (10,000 for each class)\n",
        "    n_train = 10000\n",
        "\n",
        "    # Split both positive and negative data\n",
        "    positive_train, positive_test = train_test_split(positive_data, train_size=n_train, random_state=seed)\n",
        "    negative_train, negative_test = train_test_split(negative_data, train_size=n_train, random_state=seed)\n",
        "\n",
        "    # Concatenate training sets\n",
        "    X_train = pd.concat([positive_train['review'], negative_train['review']])\n",
        "    y_train = pd.concat([positive_train['sentiment'], negative_train['sentiment']])\n",
        "\n",
        "    # Concatenate test sets\n",
        "    X_test = pd.concat([positive_test['review'], negative_test['review']])\n",
        "    y_test = pd.concat([positive_test['sentiment'], negative_test['sentiment']])\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Call the function with a specific seed for reproducibility\n",
        "seed = 42  # You can change the seed to test different splits\n",
        "X_train, X_test, y_train, y_test = split_data(positive_data, negative_data, seed)\n",
        "\n",
        "# Checking the shapes of the splits\n",
        "print(\"Training Data - X:\", X_train.shape, \"y:\", y_train.shape)\n",
        "print(\"Test Data - X:\", X_test.shape, \"y:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwsbB1EiJyiE",
        "outputId": "37f671a3-41e4-4ae0-e591-8de2cefeda73"
      },
      "id": "AwsbB1EiJyiE",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data - X: (20000,) y: (20000,)\n",
            "Test Data - X: (4948,) y: (4948,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2: Train the Naive Bayes Model with the Training Set\n",
        "# Compute word frequencies for the training data\n",
        "freqs = review_counter({}, X_train, y_train)\n",
        "\n",
        "# Train Naive Bayes to get logprior and loglikelihood\n",
        "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG_8Pj9HKtrm",
        "outputId": "90870bd7-c2a6-4e6f-d5e9-13ffd3276b6d"
      },
      "id": "xG_8Pj9HKtrm",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.6931471805599453\n",
            "43606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#3: Test the Naive Bayes Model on both the training and test sets\n",
        "\n",
        "# Confusion matrix for the training set\n",
        "train_accuracy = test_naive_bayes(X_train, y_train, logprior, loglikelihood)\n",
        "train_predictions = [naive_bayes_predict(review, logprior, loglikelihood) for review in X_train]\n",
        "train_cm = confusion_matrix(y_train, train_predictions)\n",
        "print(f\"Confusion Matrix (Training Set):\\n{train_cm}\")\n",
        "\n",
        "# Confusion matrix for the test set\n",
        "test_accuracy = test_naive_bayes(X_test, y_test, logprior, loglikelihood)\n",
        "test_predictions = [naive_bayes_predict(review, logprior, loglikelihood) for review in X_test]\n",
        "test_cm = confusion_matrix(y_test, test_predictions)\n",
        "print(f\"Confusion Matrix (Test Set):\\n{test_cm}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C7yy-sfMfWa",
        "outputId": "b49e3208-b61a-4506-85a1-3cad58e95645"
      },
      "id": "6C7yy-sfMfWa",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Training Set):\n",
            "[[9536  464]\n",
            " [1260 8740]]\n",
            "Confusion Matrix (Test Set):\n",
            "[[2267  207]\n",
            " [ 446 2028]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4: Examine False Positives and False Negatives\n",
        "\n",
        "# Get False Positives and False Negatives\n",
        "false_positives = [review for review, pred, true in zip(X_test, test_predictions, y_test) if pred == 1 and true == 0]\n",
        "false_negatives = [review for review, pred, true in zip(X_test, test_predictions, y_test) if pred == 0 and true == 1]\n",
        "\n",
        "print(f\"Number of False Positives: {len(false_positives)}\")\n",
        "print(f\"Number of False Negatives: {len(false_negatives)}\")\n",
        "\n",
        "# Print a few examples of false positives and false negatives\n",
        "print(\"\\nFalse Positives Example Reviews:\")\n",
        "for review in false_positives[:5]:\n",
        "    print(review)\n",
        "\n",
        "print(\"\\nFalse Negatives Example Reviews:\")\n",
        "for review in false_negatives[:5]:\n",
        "    print(review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMtFKZHxNBQc",
        "outputId": "126d3550-8c2f-4dc5-cf73-cc3c9cf722c8"
      },
      "id": "CMtFKZHxNBQc",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of False Positives: 207\n",
            "Number of False Negatives: 446\n",
            "\n",
            "False Positives Example Reviews:\n",
            "DD films were damn corny, damn stupid and had a plot which seemed wafer thin but those days they was a plot at least<br /><br />This film isn't just a comedy but a mix of melodrama, romance everything<br /><br />Every drama scene is blown out of proportion<br /><br />The comedy is funny but corny too Yet the film keeps you entertained, those days Govinda films were loud, crass yet they had some funny moments people enjoyed<br /><br />David Dhawan does a okay job Music is okay<br /><br />Govinda acts well in comedy and drama Karisma is decent in parts and annoys in parts Kader is as usual Gulshan, Prem Chopra are typecast Shakti is hilarious\n",
            "As an avid Gone With the Wind fan, I was disappointed to watch the original movie and see that they had left out many important characters. Luckily, the film on its own was a wonderful piece. When the book Scarlett came out, I read it in hopes of following two of my favorite literary characters farther on their journey together. While the book lacks any true quality, it remains a good story, and, as long as I was able to separate it from the original, was and still is enjoyable. However, I consider the six hours I spent watching the \"Scarlett\" miniseries to be some of the worst-spent hours of my life. Discrediting any of the original character traits so well-formed in Margaret Mitchell's book, this series also turned the story of the sequel into one of rape, mistrust, murder, and misformed relationships that even the book Scarlett stayed away from. The casting for many of the characters refused to examine the traits that had been so well-formed in both the original novel and film, and even carried through in the second book, and again leaves out at least one incredibly crucial character. In the novel, Scarlett O'Hara Butler follows her estranged husband Rhett Butler to Charleston under the guise of visiting extended family. After coming to an \"arrangement\" with Rhett, she agrees to leave, and proceeds to reconnect with her O'Hara relatives in Savannah. Eventually, she accompanies her cousin Colum, a passionate leader of the Fenian Brotherhood, to Ireland, to further explore her family's \"roots that go deep,\" and is eventually named \"The O'Hara,\" the head of the family. While her duties as The O'Hara keep her engaged in her town of Ballyhara, Scarlett ventures out into the world of the English landowners, and instantly becomes a sought-after guest at many of their parties. She, having been scorned by Rhett time and time again, eventually agrees to marry Luke, the earl of Fenton, until Rhett comes along in a clichÃ©d \"night-on-white-horse\" - type of a rescue. The \"Scarlett\" miniseries fails even to do this justice. Raped by her fiancÃ© and scorned by her family, the series shows Scarlett thrown in jail after she is blamed for a murder her cousin committed.<br /><br />I heartily advise anyone considering spending their day watching this to rethink this decision.\n",
            "Jean Seberg had not one iota of acting talent. Like all her films, 'Bonjour tristesse' suffers not at all from her looks (though she is perhaps the first of those modern women whom Tom Wolfe gleefully, accurately describes as \"boys with breasts\": publicists, of course, use the word \"gamine\") but suffers grievously from Seberg's dull, monotonous, killing voice. In all her films when had to play anger, Seberg played it with grossly audible, distracting, gasping panting between her monotonously droned verbalizations. Oy.<br /><br />Preminger's adaptation of FranÃ§oise Sagan's breathlessly juvenile, fantasy soap opera plot is noteworthy only for his lush cinematography - but then that's difficult to funk on the photogenic French Riviera, and perhaps for his apt, but certainly not groundbreaking, employment of black & white for the present day scenes from which Seberg's monotone narration delivers us to the flashed-back-to color past.<br /><br />Juliette GrÃ©co has a brief moment, as a nightclub chanteuse in the black & white spotlight, delivering in smoky Dietrichesque voice the bleak existentialist lyric of the title song. This moment is nowadays, in retrospect, more than a wee bit drÃ´le. Except, of course, if you're French - particularly if you're a French \"68-er\" longing for the glorious days of the barricades roundabout the Sorbonne - and your kids riot to retain the lifelong sinecures which have blighted and emasculated France's economy: then you still believe in Sartre and Foucault and all such arcane, irrelevant theorists.<br /><br />David Niven has the hardest role, having to play with sufficient gusto an aging hedonist who's yet to grasp that life isn't all about Sagan's teenybopper notions of a hip, cool, swingin', \"mon copain!\" Papa. Deborah Kerr delivers her usual, consummately professional presence, convincingly playing the woman who suffers undeservedly Seberg's spiteful teenaged snot-nose jealousy (fulfilling Sagan's shallow teen fantasy of the Classical theme of \"there can be only one Queen Bee in the hive\"); in fact, to Kerr belongs this film's sole great and memorable on-screen moment.<br /><br />The dialogue is unnatural - I agree with an earlier reviewer who said that it sounds to be \"badly translated\" from French; combine the unnatural scripting with Seberg's incomparably dull, unendurable monotone and you can save that Valium for another night. Atop all that the ineptly synched post-production voice dubbing is, almost throughout, obvious and thus much more than irksome: this is especially true of the dubbing for MylÃ¨ne Demongeot because it spoils her otherwise very pleasing dumb blonde performance.<br /><br />Hunky Geoffrey Horne gets the short end of the stick here - a very good looking young man who also suffered from a less-than-lovely, uncinematic voice which, when paired with Seberg's drone, yields unconvincing scenes of puppy love. (Horne was, shall we say, merely adequate in 'Bridge On the River Kwai,' perhaps because his end was held up by those great cinema pros William Holden and Jack Hawkins instead of being unsupported by the regrettably ungifted Seberg).<br /><br />In sum 'Bonjour tristesse' is pretty to look at but it's shallow, immature soap: thin gruel with suds.\n",
            "I recently watched Belle Epoque, thinking it might be wonderful as it did win an Oscar for Best Foreign Language Film. I was a bit underwhelmed by the predictability and simplicity of the film. Maybe the conflict I had was that from the time the movie was filmed to now, the plot of a man falling for beautiful women and eventually falling for the good girl has been done so many times. Aside from predictability of the plot, some scenes in the film felt really out of place with the storyline (ex. a certain event at the wedding). At times the film was a bit preachy in it's ideas and in relation to the Franco era the film was set in and the Church. The only thing the film had going for it was the cutesy moments, the scenery, and the character of Violeta being a strong, independent woman during times when women were not really associated with those characteristics.\n",
            "It's partly bad luck for \"Illuminata\" that it comes out after \"Shakespeare in Love\" as it deals with virtually the same themes of life as art, art as life and the Magic of the Theatre and the same archetypal Foibles of Theater Folk, but a whole lot more ponderously.<br /><br />There are scenes that come alive, as a play develops and gets reinterpreted by a writer's life, but there's a whole lot of Orson Welles-ish ego in this produced by/directed by/lead acted by John Torturro as a vehicle for his wife Katharine Borowitz (with an adorable cameo by their son).<br /><br />Each actor gets his/her moment literally in the spotlight, but there's so many \"masques\" or set pieces that seem like 19th century parlor games. Bill Irwin Talks. Susan Sarandon gets to be a diva. Christopher Walken gets to be a different kind of villain - a gay critic. The women have to disrobe unnecessarily because this is an Art Film.<br /><br />The art and set direction are marvelous, though quite dark. This should get an award as the Best Use of a Jersey City Theater as A Set Ever In a Movie. (originally written 8/21/99)\n",
            "\n",
            "False Negatives Example Reviews:\n",
            "I really enjoyed this movie - I like prison movies in general (I'm not sure why -- I'm sure some shrink could make something out of it!) I spent one night in jail more than 20 years ago, and I knew then I would never go back - I got the individual version of \"scared straight\"! (I did get locked up in an isolation cell on Alcatraz for a couple of hours, compliments of a park ranger, but that's another story!) Anyway, the genre really interests me. The soundtrack, specifically \"Sympathy for the Devil\" by the Rolling Stones, was the perfect backdrop for the film. To this day, I think of \"The Jericho Mile\" every time I hear the song.\n",
            "This is by far one of my favorite of the American Pie Spin offs mainly because in most of the others the main character (one of the young Stiflers) always seems unrealistic in nature. <br /><br />For example AP: The Naked Mile. You have a teenage guy surrounded by naked college chicks , and has one in particular hot on his trail to rid him of his virginity \"problem\" and he ends up stopping mid-deed and rides a horse back to sleep with his girlfriend, who keep in mind gave him a \"guilt free pass\" for the weekend. I can appreciate the romantic aspect of the whole thing but let's be realistic; most people who are watching these movies aren't particularly searching for a romantic story.<br /><br />Whereas the most recent installment finally seems to realize who the audience is and good old Erik Stifler seems to wake up and smell the roses and as always Mr. Levenstein lends his \"perfectly natural\" eyebrow humor to the equation and scored a touchdown with this new movie.\n",
            "OK, I don't really think that Trailer Park Boys has bad story lines, because they kick ass. They just... conflict with each other.<br /><br />For Example: Near the end of the movie, it shows Ricky and Julian telling \"Patrick Lewis\" to put the dog down and walk away. Then at the end, it shows Ricky and Julian saying that they've been in jail for 2 years. In the TV series pilot, the first clip they show is the same clip of Ricky and Julian yelling at \"Patrick Lewis\". But in the TV series, they've supposedly only been in jail for 18 months.<br /><br />Also, they give us the impression that the movie's story line and the TV series' story line are connected (because of the yelling scene between the guys). But some actors portray totally different characters. Of course, Patrick Roach plays \"Patrick Lewis\" in the movie, but in the series he plays Randy. Sam Tarasco plays one of the guys who pays Ricky for an extermination, and then he plays Sam Losco in the series.<br /><br />Also (again... I know, I have a lot to say), in the movie, the guys snort coke instead of smoking hash. The thing is, they never actually confirm that the two story lines are connected in anyway, other than the yelling scene.<br /><br />Sorry to keep on blabbing.\n",
            "The opening scene of this movie is pretty incredible. I've seen a number of sci-fi movies with great special effects but my roommate and I looked at each other after the opening sequence and he said plainly, \"sensory overload.\" The plot of the movie is pretty simple but the nice thing about this sci-fi movie is that it lets the audience figure out most of the technology for themselves instead of wasting time to \"subtly\" explain it. The creatures in this movie are also very interesting. You don't get a really good look at them until about two thirds of the way through. Overall, a very entertaining movie.\n",
            "If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e6e4d1",
      "metadata": {
        "id": "82e6e4d1"
      },
      "source": [
        "# Q8. Theory Questions: (15 points)\n",
        "\n",
        "1. Why is Laplace Smoothing or Additive Smoothing required while executing Naive Bayes operations, especially for text classification? (10 points)\n",
        "\n",
        "\n",
        "2. Why are logarithmic values computed instead of only probability values in the Naive Bayes algorithm? (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer:\n",
        "1.\n",
        "- Laplace Smoothing (or Additive Smoothing) is required in Naive Bayes, especially for text classification tasks, to handle situations where a word from the test set doesn't appear in the training set.\n",
        "- Laplace smoothing prevents zero probability when an unseen word appears in the test data. If a word is not in the training set, its probability would be zero, which would nullify the entire document’s classification.\n",
        "- By adding a small constant (usually 1) to all word counts, it ensures that no probability is ever zero. This improves model robustness, avoids overfitting and generalizes better to new, unseen data.\n",
        "\n",
        "2.\n",
        "\n",
        "- Logarithmic values are used to avoid underflow that occurs when multiplying many small probabilities, which could lead to very small numbers that computers can't handle.\n",
        "- Logarithms convert multiplication into addition, simplifying calculations and improving numerical stability. They also make the model more efficient and easier to interpret."
      ],
      "metadata": {
        "id": "XmYsEI5YOXkK"
      },
      "id": "XmYsEI5YOXkK"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}